{"meta":{"title":"天雷","subtitle":"一步一个脚印,成长举足之间","description":null,"author":"skyRay","url":"http://54skyray.cn"},"pages":[{"title":"标签","date":"2018-08-22T02:58:30.000Z","updated":"2018-08-22T02:59:37.441Z","comments":true,"path":"tags/index.html","permalink":"http://54skyray.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"springcloud netflix全家桶学习笔记（上）","slug":"2021-08-02-springcloud-netflix全家桶学习笔记（上）","date":"2021-08-01T17:23:47.000Z","updated":"2021-10-19T05:56:07.028Z","comments":true,"path":"2021/08/02/2021-08-02-springcloud-netflix全家桶学习笔记（上）/","link":"","permalink":"http://54skyray.cn/2021/08/02/2021-08-02-springcloud-netflix全家桶学习笔记（上）/","excerpt":"前言netflix开源框架学习包含：Eureka、Ribbon、Feign、Hystrix、zuul 本文仅包含Eureka、Ribbon","text":"前言netflix开源框架学习包含：Eureka、Ribbon、Feign、Hystrix、zuul 本文仅包含Eureka、Ribbon 正文微服务与微服务架构微服务强调服务的大小，关注的是具体解决一个问题/提供落地对应服务的一个服务应用，狭义就是一个Modules 微服务架构一种新的架构形式 由Martin Fowler 2014提出 微服务架构是一种架构模式，它提倡将单一应用程序划分为一组小的服务，服务之间互相协调配合，为用户提供价值 微服务优缺点优点 单一职责原则 单一服务足够内聚、足够小、代码容易理解。聚焦一个业务或业务需求 微服务能被小团队单独开发 服务松耦合，有功能意义的服务，无论是在开发阶段或不熟阶段都是独立的 能使用不同的语言开发 易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如jenkins、Hudson、bamboo 微服务易于理解，修改维护、无需合作就能体现价值 允许你利用融合最新技术 微服务只是业务逻辑的代码 每个微服务都可以有自己的存储能力或使用统一数据库 缺点 开发人员需处理分布式系统带来的复杂性 多服务运维难度，随服务增加而增加 系统依赖部署 服务间通讯成本 数据一致性 系统集成测试 性能监控难 微服务技术栈 微服务条目 落地技术 服务开发 SpringBoot、Spring、SpringMVC 服务配置与管理 Netflix公司的Archaius、阿里的Diamond 服务注册与发现 Eureka、Consul、Zookeeper 服务调用 Rest、RPC、gRPC 服务熔断 Hystrix、Envoy 负载均衡 Ribbon、Nginx 服务接口调用（客户端调用服务简化工具） Feign 消息队列 Kafka、RabbitMQ、ActiveMQ 服务配置中心管理 SpringCloudConfig、Chef 服务路由（API网关） Zuul 服务监控 Zabbix、Nagios、Metrics、Specatator 全链路追踪 Zipkin、Brave、Dapper 服务部署 Docker、OpenStack、kubernates 数据流操作开发包 SpringCloud Stream(封装与Redis、Rabbit、Kafka等发送接受消息) 事件消息总线 SpringCloud Bus 为什么选SpringCloud作为微服务框架1、选型依据 整体解决方案和框架成熟度 社区热度 可维护性 学习曲线 2、当前各大IT公司用的微服务有哪些 阿里 dubbo+HSF 京东 JSF 新浪 Motan 当当网 Dubbox 3、各微服务框架对比常用搭配spring cloud Netflix 一站式解决方案api网关 zuul Feign—HttpClient—Http通信方式 同步 阻塞 服务注册发现 Eureka 熔断机制 hystrix Apache Dubbo Zookeeper半自动需要整合第三方Api 没有，第三方或自研 Dubbo Zookeeper 没有 借 Hystrix Spring Cloud Alibaba一站式解决方案！更简单新概念 服务网格！~ServerMeshistio 万变不离其宗 api Http Rpc 注册与发现 熔断 Eureka一句话简介Eureka是Netflix的子模块，基于REST服务，实现服务发现和故障转移，类似于Dubbo的注册，如Zookeeper Eureka组件包含Eureka Server 和Eureka Client Eureka Server提供服务注册，节点启动后会在该组件注册。 Eureka Client是Java客户端，用于简化Eureka Server交互，使用轮训负载算法的负载均衡器，应用启动后会向Eureka Server发送心跳（默认走起30秒）。当Eureka Server多个心跳周期未收到节点的心跳，将会把服务节点移除（默认周期90秒） 三个角色 Eureka Server 服务注册与发现 Service Provider 将自身服务注册到Eureka，方能消费得到 Service Comsumer 从Eureka获取注册服务列表，方能消费服务 引入步骤 创建Eureka监控项目 引pom 配置端口、eureka信息 开启@enableEurekaClient 服务注册者 引pom 配置端口、eureka信息 开启@enableEurekaServer 冗余 -&gt;可通过actuator依赖来完善eureka控制台的监控信息 服务消费者 引pom 开启@enableEurekaClient Eureka比Zookeeper好在哪里关于CAP理论，一个分布式系统不可能同时满足C（一致性）、A（可用性）、P（容错性） Zookeeper保证的是CP 当一台master服务宕机，重新选举时间太长（30~120s），这个期间服务相当于瘫痪 Eureka保证的是AP 每个节点平等，节点连接失效会自动切换其他节点，如果15min出现85%的节点没有正常心跳，会出现自我保护机制，如下： Eureka不再从注册列表中移除长时间未收到心跳该过期的服务 Eureka仍然接受新服务的注册和查询请求，但是不会同步其他节点（保证当前节点依然可用） 当网络稳定，当前实例新的注册信息会被同步到其他节点 Eureka更多 自我保护机制 当服务提供心跳停止30秒会注销这个服务 但是大批量提供者停止心跳，会被认为是网络事故等，会停止注销保留服务注册信息 通过api获取所有服务提供者。以及指定服务提供者的服务 Eureka集群搭建 搭建三个一样的项目 引入依赖 修改配置文件，互相依赖 修改hosts 写启动类 客户端引用方式 ribbonribbon是Spring Cloud Ribbon基于Netflix Ribbon实现的客户端负载均衡工具。 提供客户端的软件负载均衡算法，将Netflix的中间服务连接在一起，提供一系列完整配置项如：连接超时、重试等。Ribbon基于某种规则（简单轮训、随机连接等）去连接各种服务。 一句话原理通过eureka集群获取服务列表，根据配置的规则进行服务的LB 配置方式 引入依赖 spring-cloud-starter-netflix-eureka-client 就包含了ribbon 配置 1234567eureka: instance: instance-id: springcloud-consumer-80 client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ register-with-eureka: false 在请求端RestTemplatez实例上加@LoadBalanced 12345@Bean@LoadBalancedpublic RestTemplate restTemplate()&#123; return new RestTemplate();&#125; 我们这边http请求前缀可以改成服务名 12// public static final String REST_URL_PERFIX = \"http://localhost:8001\"; public static final String REST_URL_PERFIX = \"http://EUREKA-PROVIDER-DEPT\"; 这个前缀名字来自于服务提供者的spring.applicaiton.name 可以配置哪些规则来进行LB通过源码IRule相关方法重写来实现不同的规则，如下 1234@Beanpublic IRule myRule()&#123; return new RandomRule();&#125; 也可以在微服务启动时就去加载我们自定义的Ribbon类 首先在启动类加上注解 1@RibbonClient(name = \"EUREKA-PROVIDER-DEPT\",configuration = RayRule.class) 规则类RayRule.class不能与启动类在同一个包级别下,原因如下 FooConfiguration必须是@Configuration，但请注意，主应用程序上下文不属于@ComponentScan，否则将由@RibbonClients共享。如果您使用@ComponentScan（或@SpringBootApplication），则需要采取措施避免包含（例如将其放在一个单独的，不重叠的包中，或者指定要在@ComponentScan）。 [^来自springcloud官方文档]: https://www.springcloud.cc/spring-cloud-netflix.html 结文中阐述不妥之处还望雅正，不吝感激。 转载请注明:天雷 以上。","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"http://54skyray.cn/tags/架构/"},{"name":"springcloud","slug":"springcloud","permalink":"http://54skyray.cn/tags/springcloud/"},{"name":"eureka","slug":"eureka","permalink":"http://54skyray.cn/tags/eureka/"},{"name":"ribbon","slug":"ribbon","permalink":"http://54skyray.cn/tags/ribbon/"}]},{"title":"B站架构分享笔记","slug":"b站高可用架构","date":"2021-08-01T17:23:47.000Z","updated":"2021-08-03T15:03:21.084Z","comments":true,"path":"2021/08/02/b站高可用架构/","link":"","permalink":"http://54skyray.cn/2021/08/02/b站高可用架构/","excerpt":"前言最近看了B站首席技术分享B站架构，虽然不能付诸实践，但是却在脑海中打下地基，以后出现服务事故也可往该方向优化，毕竟我个人也一直在刷B站觉得体验是很好的。有一部分直接拷贝的大佬总结。觉得已经总结的很好无需添油加醋","text":"前言最近看了B站首席技术分享B站架构，虽然不能付诸实践，但是却在脑海中打下地基，以后出现服务事故也可往该方向优化，毕竟我个人也一直在刷B站觉得体验是很好的。有一部分直接拷贝的大佬总结。觉得已经总结的很好无需添油加醋 正文负载均衡负载均衡具体分成两个方向，一个是前端负载均衡，另一个是数据中心内部的负载均衡。 前端负载均衡前端负载均衡方面，一般而言用户流量访问层面主要依据DNS，希望做到最小化用户请求延迟。将用户流量最优地分布在多个网络链路上、多个数据中心、多台服务器上，通过动态CDN的方案达到最小延迟。以上图为例，用户流量会先流入BFE的前端接入层，第一层的BFE实际上起到一个路由的作用，尽可能选择跟接入节点比较近的一个机房，用来加速用户请求。然后通过API网关转发到下游的服务层，可能是内部的一些微服务或者业务的聚合层等，最终构成一个完整的流量模式。 基于此，前端服务器的负载均衡主要考虑几个逻辑： 第一，尽量选择最近节点； 第二，基于带宽策略调度选择API进入机房； 第三，基于可用服务容量平衡流量。 数据中心内部负载均衡数据中心内部的负载均衡方面，理想情况下会像上图右边显示那样，最忙和最不忙的节点所消耗的CPU相差幅度较小。但如果负载均衡没做好，情况可能就像上图左边一样相差甚远。由此可能导致资源调度、编排的困难，无法合理分配容器资源。因此，数据中心内部负载均衡主要考虑： 均衡流量分发； 可靠识别异常节点； scale-out，增加同质节点以扩容； 减少错误，提高可用性。 子集选择和多集群我们此前通过同质节点来扩容就发现，内网服务出现CPU占用率过高的异常，通过排查发现背后RPC点到点通信间的 healthCheck 成本过高，产生了一些问题。另外一方面，底层的服务如果只有单套集群，当出现抖动的时候故障面会比较大，因此需要引入多集群来解决问题。通过实现 client 到 backend 的子集连接，我们做到了将后端平均分配给客户端，同时可以处理节点变更，持续不断均衡连接，避免大幅变动。多集群下，则需要考虑集群迁移的运维成本，同时集群之间业务的数据存在较小的交集。 CPU忙时、闲时占用率过大问题，与负载均衡算法有关 实质上每一次请求，成本都是不同的，节点的差异非常大，即使均衡的流量分发，负载旧是不均匀 物理机环境，CPU的型号不同主频不一致也导致，服务器负载很难做到同质化 基于此，参考JSQ（最闲轮训）负载均衡算法带来的问题，发现缺乏的是服务端全局视图，因此我们的目标需要综合考虑负载和可用性。我们参考了《The power of two choices in randomized load balancing》的思路，使用the choice-of-2算法，随机选取的两个节点进行打分，选择更优的节点： 选择backend：CPU，client：health、inflight、latency作为指标，使用一个简单的线性方程进行打分； 对新启动的节点使用常量惩罚值（penalty），以及使用探针方式最小化放量，进行预热； 打分比较低的节点，避免进入“永久黑名单”而无法恢复，使用统计衰减的方式，让节点指标逐渐恢复到初始状态（即默认值）。 正因如此，参考JSQ（最闲轮训）负载均衡算法带来的问题，发现缺乏的是服务端全局视图，因此我们的目标需要综合考虑负载和可用性。我们参考了《The power of two choices in randomized load balancing》的思路，使用the choice-of-2算法，随机选取的两个节点进行打分，选择更优的节点： 选择backend：CPU，client：health、inflight、latency作为指标，使用一个简单的线性方程进行打分； 对新启动的节点使用常量惩罚值（penalty），以及使用探针方式最小化放量，进行预热； 打分比较低的节点，避免进入“永久黑名单”而无法恢复，使用统计衰减的方式，让节点指标逐渐恢复到初始状态（即默认值）。 限流限流的要点避免过载，是负载均衡的重要目标。随着压力增加，无论均衡策略如何高效，系统某个部分总会过载。此时优先考虑优雅降级，返回低质量的结果，有损服务(如推荐系统，本来时个性化推荐，有损后只推荐热门)。最差的情况，妥善的限流保证服务本身稳定。 QPS陷阱 请求成本不同 静态阈值难以配置，CPU、内存不同如何给与不一样的负载（思考：基于CPU售卖不同服务） 按照优先级丢弃 给每个用户设置限制 全局过载发生时候，针对某些“异常”进行控制非常关键 拒绝请求也是成本 负载依据 服务端主要cpu（k8s负载调度参考的cpu） 客户端主要健康度 （连接成功率） 限流就是自保，我们任务主要关注以下几点 一是针对qps的限制，带来请求成本不同、静态阈值难以配置的问题； 二是根据API的重要性，按照优先级丢弃； 三是给每个用户设置限制，全局过载发生时候，针对某些“异常”进行控制非常关键； 四是拒绝请求也需要成本； 五是每个服务都配置限流带来的运维成本。 分布式限流Quota Server客户端侧截流(熔断)依赖服务如mysql、reids错误率太高时。可以直接考虑截流，对下游起到一定保护作用. 过载保护假如没有过载保护，服务器因过载宕机，其余流量密集在剩下的服务器，会因流量过大导致雪崩（服务器大量宕机）。 在过载保护方面，核心思路就是在服务过载时，丢弃一定的流量，保证系统临近过载时的峰值流量，以求自保护。常见的做法有基于CPU、内存使用量来进行流量丢弃；使用队列进行管理；可控延迟算法：CoDel 等。简单来说，当我们的CPU达到80%的时候，这个时候可以认为它接近过载，如果这个时候的吞吐达到100，瞬时值的请求是110，我就可以丢掉这10个流量，这种情况下服务就可以进行自保护，我们基于这样的思路最终实现了一个过载保护的算法。CPU滑动阈值（cpu&gt;800)作为启发阈值，并且使用冷却时间(小于保护后的冷却时间) 重试重试策略 流量的走向，一般会从BFE到LB（负载均衡）然后经过API网关再到BFF、微服务最后到数据库，这个过程要经过非常多层。在我们的日常工作中，当请求返回错误，对于backend部分节点过载的情况下，我们应该怎么做？ 首先我们需要限制重试的次数，以及基于重试分布的策略； 其次，我们只应该在失败层进行重试，当重试仍然失败时，我们需要全局约定错误码，避免级联重试； 此外，我们需要使用随机化、指数型递增的充实周期，这里可以参考Exponential Backoff和Jitter； 最后，我们需要设定重试速率指标，用于诊断故障。 客户端限速用户积极重试，访问一个不可达的服务，限制客户客户端请求频次，Backoff做一定的请求退让，通过接口级别的error_detail，挂载导每个api返回的响应里，让移动端感知服务端策略。 超时进程内超时控制大部分的故障都是因为超时控制不合理导致的。首当其冲的是高并发下的高延迟服务，导致client堆积，引发线程阻塞，此时上游流量不断涌入，最终引发故障。所以，从本质上理解超时它实际就是一种Fail Fast的策略，就是让我们的请求尽可能消耗，类似这种堆积的请求基本上就是丢弃掉或者消耗掉。 跨进程超时控制超时传递,上游服务超时时间&gt;下游服务超时时间 全链路压测阿里做法，引流到私有集群，私有集群不涉及普通用户数据 总结（应对连锁事故） 第一，我们需要尽可能避免过载。因为节点一个接一个挂了的话，最终服务会雪崩，有可能机群都会跟着宕掉，所以我们才提到要做自保护。 第二，我们通过一些手段去做限流。它可以让某一个client对服务出现高流量并发请求时进行管控，这样的话服务也不容易死。另外，当我们无法正常服务的时候，还可以做有损服务，牺牲掉一些非核心服务去保证关键服务，做到优雅降级。 第三，在重试策略上，在微服务内尽可能做退避，尽可能要考虑到重试放大的流量倍数对下游的冲击。另外还要考虑在移动端用户用不了某个功能的情况下，通常会频繁刷新页面，这样产生的流量冲击，我们在移动端也要进行配合来做流控。 第四，超时控制强调两个点，进程内的超时和跨进程的传递。最终它的超时链路是由最上层的一个节点决定的，只要这一点做到了，我觉得大概率是不太可能出现连锁故障的。 第五，变更管理。我们通常情况下发布都是因为一些变更导致的，所以说我们在变更管理上还是要加强，变更流程中出现的破坏性行为应该要进行惩罚，尽管是对事不对人，但是还是要进行惩罚以引起重视。 第六，极限压测和故障演练。在做压测的时候，可能压到报错就停了。我建议最好是在报错的情况下，仍然要继续加压，看你的服务到底是一个什么表现？它能不能在过载的情况下提供服务？在上了过载保护算法以后，继续加压，积极拒绝，然后结合熔断的话，可以产生一个立体的保护效果。 经常做故障演练可以产生一个品控手册，每个人都可以学习，经常演练不容易慌乱，当在生产环境中真的出现问题时也可以快速投入解决。 第七，考虑扩容、重启、消除有害流量。 结文中阐述不妥之处还望雅正，不吝感激。 转载请注明:天雷 以上。","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"http://54skyray.cn/tags/架构/"}]},{"title":"一次非常规FULLGC记录","slug":"诡异的FULL_GC","date":"2020-05-19T01:36:58.000Z","updated":"2020-11-25T03:04:38.352Z","comments":true,"path":"2020/05/19/诡异的FULL_GC/","link":"","permalink":"http://54skyray.cn/2020/05/19/诡异的FULL_GC/","excerpt":"前言mark","text":"前言mark 正文公司的一台线上服务器突然宕机。立马关掉slb 开始排查123456789101112131415161718192019-09-17T20:33:57.889+0800: 4753520.554: [Full GC (Metadata GC Threshold) 4753520.554: [CMS[YG occupancy: 723220 K (1887488 K)]4753520.988: [weak refs process ing, 0.0042134 secs]4753520.992: [class unloading, 0.0987343 secs]4753521.091: [scrub symbol table, 0.0237609 secs]4753521.115: [scrub string table, 0.0025983 s ecs]: 145423K-&gt;141376K(3354624K), 0.6260023 secs] 868644K-&gt;864597K(5242112K), [Metaspace: 128179K-&gt;128179K(1234944K)], 0.6264315 secs] [Times: user=1.24 sys=0.0 0, real=0.63 secs]4159962 Heap after GC invocations=8029 (full 50):4159963 par new generation total 1887488K, used 723220K [0x0000000673400000, 0x00000006f3400000, 0x00000006f3400000)4159964 eden space 1677824K, 42% used [0x0000000673400000, 0x000000069ed59090, 0x00000006d9a80000)4159965 from space 209664K, 4% used [0x00000006d9a80000, 0x00000006da36c210, 0x00000006e6740000)4159966 to space 209664K, 0% used [0x00000006e6740000, 0x00000006e6740000, 0x00000006f3400000)4159967 concurrent mark-sweep generation total 3354624K, used 141376K [0x00000006f3400000, 0x00000007c0000000, 0x00000007c0000000)4159968 Metaspace used 128145K, capacity 136860K, committed 262144K, reserved 1234944K4159969 class space used 14443K, capacity 16168K, committed 77312K, reserved 1048576K4159970 &#125;4159971 &#123;Heap before GC invocations=8029 (full 50):4159972 par new generation total 1887488K, used 723220K [0x0000000673400000, 0x00000006f3400000, 0x00000006f3400000)4159973 eden space 1677824K, 42% used [0x0000000673400000, 0x000000069ed59090, 0x00000006d9a80000)4159974 from space 209664K, 4% used [0x00000006d9a80000, 0x00000006da36c210, 0x00000006e6740000)4159975 to space 209664K, 0% used [0x00000006e6740000, 0x00000006e6740000, 0x00000006f3400000)4159976 concurrent mark-sweep generation total 3354624K, used 141376K [0x00000006f3400000, 0x00000007c0000000, 0x00000007c0000000)4159977 Metaspace used 128145K, capacity 136860K, committed 262144K, reserved 1234944K4159978 class space used 14443K, capacity 16168K, committed 77312K, reserved 1048576K 可以看到几个关键字Full GC、Metadata、 GC Threshold随后看了一下TOMCAT的JVM参数配置1CATALINA_OPTS=&quot;$CATALINA_OPTS -server -Djava.awt.headless=true -Xms5324m -Xmx5324m -Xss512k -XX:PermSize=350m -XX:MaxPermSize=350m -XX:MetaspaceSize=256m -XX:MaxMet aspaceSize=256m -XX:NewSize=2048m -XX:MaxNewSize=2048m -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=9 -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly -XX :+CMSScavengeBeforeRemark -XX:+ScavengeBeforeFullGC -XX:+UseCMSCompactAtFullCollection -XX:+CMSParallelRemarkEnabled -XX:CMSFullGCsBeforeCompaction=9 -XX:CMSInitiat ingOccupancyFraction=80 -XX:+CMSClassUnloadingEnabled -XX:SoftRefLRUPolicyMSPerMB=0 -XX:-ReduceInitialCardMarks -XX:+CMSPermGenSweepingEnabled -XX:CMSInitiatingPerm OccupancyFraction=80 -XX:+ExplicitGCInvokesConcurrent -Djava.nio.channels.spi.SelectorProvider=[sun.nio.ch](http://sun.nio.ch/).EPollSelectorProvider -Djava.util.logging.manager=org.apac he.juli.ClassLoaderLogManager -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationConcurrentTime -XX:+PrintGCApplicationStoppedTime -XX:+PrintHeapAtGC -Xloggc:/data/applogs/heap_trace.txt -XX:+IgnoreUnrecognizedVMOptions -XX:-HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/applogs/HeapDumpOnOutOfMemoryError&quot; 看到配置之后，有点懵逼，好像超出了我的认知范围 看cat监控,Metaspace基本在50%左右就FGC,GC日志也显示用了大概一半，没有达到阈值12[0x00000006f3400000, 0x00000007c0000000, 0x00000007c0000000)4159977 Metaspace used 128145K, capacity 136860K, committed 262144K, reserved 1234944K 又反复看了上面的GC片段，发现这个committed达到了阈值 我们需要知道一点：当目前的committed内存+当前需要分配的内存达到Metaspace阈值，就会发生Metadata GC Threshold的FGC。 看到这里，我们也能大概猜出了，这次FGC是合理的。 但是，为什么used指标只有125M，却还要申请其它内存？ 看来只有一个原因可以解释了：内存碎片。 之前只听过老年代因为CMS的标记清理会产生内存碎片导致FGC，为什么Metaspace也会有这样的问题？ 对有问题的机器dump了下，用mat打开之后，发现了一个新大陆，包含了大量的类加载器。 难道这个碎片问题是大量类加载器引起的？ 本地验证有了这个疑问，那就简单了，看看能不能在本地复现。1、先定义一个自定义的类加载器，破坏双亲委派12345678910111213141516171819202122232425public class MyClassLoader extends ClassLoader &#123; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try&#123; String filePath = &quot;/Users/zhanjun/Desktop/&quot; + name.replace(&apos;.&apos;, File.separatorChar) + &quot;.class&quot;; //指定读取磁盘上的某个文件夹下的.class文件： File file = new File(filePath); FileInputStream fis = new FileInputStream(file); byte[] bytes = new byte[fis.available()]; fis.read(bytes); //调用defineClass方法，将字节数组转换成Class对象 Class&lt;?&gt; clazz = this.defineClass(name, bytes, 0, bytes.length); fis.close(); return clazz; &#125;catch (FileNotFoundException e)&#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; &#125; return super.findClass(name); &#125; &#125; 2、然后在while循环中，不断的 load 已经编译好的class文件12345public static void main(String[] args) throws Exception &#123; while (true) &#123; Class clazz0 = new MyClassLoader().loadClass(&quot;com.sankuai.discover.memory.OOM&quot;); &#125; &#125; 3、最后，配置一下jvm启动参数1-Xmx2688M -Xms2688M -Xmn960M -XX:MetaspaceSize=50M -XX:MaxMetaspaceSize=100M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -XX:+UseConcMarkSweepGC 启动之后，不一会儿在控制台果然出现了日志123456789101112131415161718&#123;Heap before GC invocations=0 (full 0): par new generation total 884736K, used 330302K [0x0000000752400000, 0x000000078e400000, 0x000000078e400000) eden space 786432K, 42% used [0x0000000752400000, 0x000000076668fae0, 0x0000000782400000) from space 98304K, 0% used [0x0000000782400000, 0x0000000782400000, 0x0000000788400000) to space 98304K, 0% used [0x0000000788400000, 0x0000000788400000, 0x000000078e400000) concurrent mark-sweep generation total 1769472K, used 0K [0x000000078e400000, 0x00000007fa400000, 0x00000007fa400000) Metaspace used 22636K, capacity 102360K, committed 102400K, reserved 1118208K class space used 8829K, capacity 33008K, committed 33008K, reserved 1048576K2019-09-21T16:09:28.562-0800: [Full GC (Metadata GC Threshold) 2019-09-21T16:09:28.562-0800: [CMS: 0K-&gt;5029K(1769472K), 0.0987115 secs] 330302K-&gt;5029K(2654208K), [Metaspace: 22636K-&gt;22636K(1118208K)], 0.1340367 secs] [Times: user=0.11 sys=0.03, real=0.13 secs] Heap after GC invocations=1 (full 1): par new generation total 884736K, used 0K [0x0000000752400000, 0x000000078e400000, 0x000000078e400000) eden space 786432K, 0% used [0x0000000752400000, 0x0000000752400000, 0x0000000782400000) from space 98304K, 0% used [0x0000000782400000, 0x0000000782400000, 0x0000000788400000) to space 98304K, 0% used [0x0000000788400000, 0x0000000788400000, 0x000000078e400000) concurrent mark-sweep generation total 1769472K, used 5029K [0x000000078e400000, 0x00000007fa400000, 0x00000007fa400000) Metaspace used 2885K, capacity 4500K, committed 43008K, reserved 1058816K class space used 291K, capacity 388K, committed 33008K, reserved 1048576K&#125; 从日志可以看出来，发生FGC之前，used大概22M，committed已经达到100M，这时再加载class的时候，需要申请内存，就不够了，只能通过FGC对Metaspace的内存进行整理压缩。 到现在，我们已经验证了过多的类加载器确实可以引起FGC。 内存碎片是怎么产生的？ 其实，JVM内部为了实现高效分配，在类加载器第一次加载类的时候，会在Metaspace分配一个独立的内存块，随后该类加载加载的类信息都保存在该内存块。但如果这个类加载器只加载了一个类或者少数类，那这块内存就被浪费了，如果类加载器又特别多，那内存碎片就产生了。 结转载请注明出处:天雷 以上","categories":[],"tags":[{"name":"FullGc","slug":"FullGc","permalink":"http://54skyray.cn/tags/FullGc/"},{"name":"堆栈","slug":"堆栈","permalink":"http://54skyray.cn/tags/堆栈/"}]},{"title":"Stack Overflow上瞅到200万阅读量的一个提问：Java中怎么快速把InputStream转化为String","slug":"Stack Overflow上200万阅读量的一个提问","date":"2020-03-15T03:23:47.000Z","updated":"2020-11-23T09:41:03.274Z","comments":true,"path":"2020/03/15/Stack Overflow上200万阅读量的一个提问/","link":"","permalink":"http://54skyray.cn/2020/03/15/Stack Overflow上200万阅读量的一个提问/","excerpt":"前言整好就是一个工具包大满贯啊","text":"前言整好就是一个工具包大满贯啊 正文就是它其实我只是偶尔上Stack Overflow，直到看了这个200万次阅读量的提问： How do I read / convert an InputStream into a String in Java? 我惊呆了！！！ 怎么会有这么多人围观。 我第一反应的解决办法是使用Apache commons包的工具类IOUtils，果不其然，第一条回答就是这个。 我的天！居然有2000+的赞！ 继续往下看，发现大家的不少的骚操作 使用 CharStreams (Guava)12String result = CharStreams.toString(new InputStreamReader( inputStream, Charsets.UTF_8)); 使用 Scanner (JDK)12Scanner s = new Scanner(inputStream).useDelimiter(&quot;\\\\A&quot;);String result = s.hasNext() ? s.next() : &quot;&quot;; 使用 Stream API (Java 8).Warning: This solution converts different line breaks (like \\r\\n) to \\n.12String result = new BufferedReader(new InputStreamReader(inputStream)) .lines().collect(Collectors.joining(&quot;\\n&quot;)); 使用 parallel Stream API (Java 8).Warning: This solution converts different line breaks (like \\r\\n) to \\n.12String result = new BufferedReader(new InputStreamReader(inputStream)).lines() .parallel().collect(Collectors.joining(&quot;\\n&quot;)); 使用 InputStreamReader and StringBuilder (JDK)123456789final int bufferSize = 1024;final char[] buffer = new char[bufferSize];final StringBuilder out = new StringBuilder();Reader in = new InputStreamReader(stream, StandardCharsets.UTF_8);int charsRead;while((charsRead = in.read(buffer, 0, buffer.length)) &gt; 0) &#123; out.append(buffer, 0, charsRead);&#125;return out.toString(); 使用 StringWriter and IOUtils.copy (Apache Commons)123StringWriter writer = new StringWriter();IOUtils.copy(inputStream, writer, &quot;UTF-8&quot;);return writer.toString(); 使用 ByteArrayOutputStream and inputStream.read (JDK)12345678ByteArrayOutputStream result = new ByteArrayOutputStream();byte[] buffer = new byte[1024];int length;while ((length = inputStream.read(buffer)) != -1) &#123; result.write(buffer, 0, length);&#125;// StandardCharsets.UTF_8.name() &gt; JDK 7return result.toString(&quot;UTF-8&quot;); 使用 BufferedReader (JDK).Warning: This solution converts different line breaks (like \\n\\r) to line.separator system property (for example, in Windows to “\\r\\n”).123456789String newLine = System.getProperty(&quot;line.separator&quot;);BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream));StringBuilder result = new StringBuilder();boolean flag = false;for (String line; (line = reader.readLine()) != null; ) &#123; result.append(flag? newLine: &quot;&quot;).append(line); flag = true;&#125;return result.toString(); 使用 BufferedInputStream and ByteArrayOutputStream (JDK)123456789BufferedInputStream bis = new BufferedInputStream(inputStream);ByteArrayOutputStream buf = new ByteArrayOutputStream();int result = bis.read();while(result != -1) &#123; buf.write((byte) result); result = bis.read();&#125;// StandardCharsets.UTF_8.name() &gt; JDK 7return buf.toString(&quot;UTF-8&quot;); 使用 inputStream.read() and StringBuilder (JDK).Warning: This solution has problems with Unicode, for example with Russian text (works correctly only with non-Unicode text)123456int ch;StringBuilder sb = new StringBuilder();while((ch = inputStream.read()) != -1) sb.append((char)ch);reset();return sb.toString(); 甚至，还贴出了微基准测试的结果，果然狠人啊。 对于小字符串(length = 175) 结果如下：mode = Average Time, system = Linux, score 1,343 is the best :123456789101112 Benchmark Mode Cnt Score Error Units 8. ByteArrayOutputStream and read (JDK) avgt 10 1,343 ± 0,028 us/op 6. InputStreamReader and StringBuilder (JDK) avgt 10 6,980 ± 0,404 us/op10. BufferedInputStream, ByteArrayOutputStream avgt 10 7,437 ± 0,735 us/op11. InputStream.read() and StringBuilder (JDK) avgt 10 8,977 ± 0,328 us/op 7. StringWriter and IOUtils.copy (Apache) avgt 10 10,613 ± 0,599 us/op 1. IOUtils.toString (Apache Utils) avgt 10 10,605 ± 0,527 us/op 3. Scanner (JDK) avgt 10 12,083 ± 0,293 us/op 2. CharStreams (guava) avgt 10 12,999 ± 0,514 us/op 4. Stream Api (Java 8) avgt 10 15,811 ± 0,605 us/op 9. BufferedReader (JDK) avgt 10 16,038 ± 0,711 us/op 5. parallel Stream Api (Java 8) avgt 10 21,544 ± 0,583 us/op 对于大字符串(length = 50100) 结果如下：Performance tests for big String (length = 50100)mode = Average Time, system = Linux, score 200,715 is the best 123456789101112 Benchmark Mode Cnt Score Error Units 8. ByteArrayOutputStream and read (JDK) avgt 10 200,715 ± 18,103 us/op 1. IOUtils.toString (Apache Utils) avgt 10 300,019 ± 8,751 us/op 6. InputStreamReader and StringBuilder (JDK) avgt 10 347,616 ± 130,348 us/op 7. StringWriter and IOUtils.copy (Apache) avgt 10 352,791 ± 105,337 us/op 2. CharStreams (guava) avgt 10 420,137 ± 59,877 us/op 9. BufferedReader (JDK) avgt 10 632,028 ± 17,002 us/op 5. parallel Stream Api (Java 8) avgt 10 662,999 ± 46,199 us/op 4. Stream Api (Java 8) avgt 10 701,269 ± 82,296 us/op10. BufferedInputStream, ByteArrayOutputStream avgt 10 740,837 ± 5,613 us/op 3. Scanner (JDK) avgt 10 751,417 ± 62,026 us/op11. InputStream.read() and StringBuilder (JDK) avgt 10 2919,350 ± 1101,942 us/o 总结如获宝藏，看来需要时不时的逛逛Stack Overflow了。 结转载自:占小狼 以上。","categories":[],"tags":[{"name":"stack overflow","slug":"stack-overflow","permalink":"http://54skyray.cn/tags/stack-overflow/"}]},{"title":"所谓零拷贝","slug":"零拷贝","date":"2019-01-12T03:23:47.000Z","updated":"2019-12-30T03:23:06.619Z","comments":true,"path":"2019/01/12/零拷贝/","link":"","permalink":"http://54skyray.cn/2019/01/12/零拷贝/","excerpt":"前言晚上看到一个零拷贝，觉得算是稍微拓展一下知识面吧","text":"前言晚上看到一个零拷贝，觉得算是稍微拓展一下知识面吧 正文简单拷贝场景从一个文件中独处数据并将数据传到另一台服务器上，我们的常规操作是 File.read(file, buf, len); Socket.send(socket, buf, len); 这种方式设计了4次拷贝，文字有点干瘪，上图1、应用程序中调用read()方法，这里会涉及到一次上下文切换（用户态-&gt;内核态），底层采用DMA（direct memory access）读取磁盘的文件，并把内容存储到内核地址空间的读取缓存区。 2、由于应用程序无法读取内核地址空间的数据，如果应用程序要操作这些数据，必须把这些内容从读取缓冲区拷贝到用户缓冲区。这个时候，read() 调用返回，且引发一次上下文切换（内核态-&gt;用户态），现在数据已经被拷贝到了用户地址空间缓冲区，这时，如果有需要，应用程序可以操作修改这些内容。 3、我们最终目的是把这个文件内容通过Socket传到另一个服务中，调用Socket的send()方法，这里又涉及到一次上下文切换（用户态-&gt;内核态），同时，文件内容被进行第三次拷贝，被再次拷贝到内核地址空间缓冲区，但是这次的缓冲区与目标套接字相关联，与读取缓冲区没有半点关系。 4、send()调用返回，引发第四次的上下文切换，同时进行第四次的数据拷贝，通过DMA把数据从目标套接字相关的缓存区传到协议引擎进行发送。 过程1和4是由DMA负责，并不会消耗CPU，只有过程2和3的拷贝需要CPU参与 零拷贝常规操作是否感觉好几次拷贝很多余，接下来便是零拷贝的方式 这种实现，可以有以下几点改进： 上下文切换的次数从四次减少到了两次 数据拷贝次数从四次减少到了三次（其中DMA copy 2次，CPU copy 1次） “在Java中，正好FileChannel的transferTo() 方法可以实现这个过程，该方法将数据从文件通道传输到给定的可写字节通道， 上面的file.read()和 socket.send() 调用动作可以替换为transferTo() 调用” public void transferTo(long position, long count, WritableByteChannel target); 在 UNIX 和各种 Linux 系统中，此调用被传递到 sendfile() 系统调用中，最终实现将数据从一个文件描述符传输到了另一个文件描述符。 继续优化？在 Linux 内核 2.4 及后期版本中，针对套接字缓冲区描述符做了相应调整，DMA自带了收集功能，对于用户方面，用法还是一样的，但是内部操作已经发生了改变： 第一步，transferTo() 方法引发 DMA 将文件内容拷贝到内核读取缓冲区。 第二步，把包含数据位置和长度信息的描述符追加到套接字缓冲区，避免了内容整体的拷贝，DMA 引擎直接把数据从内核缓冲区传到协议引擎，从而消除了最后一次 CPU参与的拷贝动作。 结该文引用自https://www.jianshu.com/p/2581342317ce 文中阐述不妥之处还望雅正，不吝感激。 转载请注明:天雷 以上。","categories":[],"tags":[{"name":"socket","slug":"socket","permalink":"http://54skyray.cn/tags/socket/"},{"name":"copy","slug":"copy","permalink":"http://54skyray.cn/tags/copy/"}]},{"title":"一次docker的数据库迁移","slug":"一次docker数据库迁移","date":"2018-08-10T10:22:23.000Z","updated":"2019-12-06T08:13:57.625Z","comments":true,"path":"2018/08/10/一次docker数据库迁移/","link":"","permalink":"http://54skyray.cn/2018/08/10/一次docker数据库迁移/","excerpt":"前言网上看到的一个文章，虽然对docker相对比较熟悉。但是没有做过类似的实践，记录一次本地尝试.","text":"前言网上看到的一个文章，虽然对docker相对比较熟悉。但是没有做过类似的实践，记录一次本地尝试. 正文之前使用的 MySql 跟 MongoDb 都是基于 Docker 部署的，所以迁移起来还算比较方便，主要思路就是把数据库容器的数据卷单独做成一个数据镜像，然后把这个镜像提交到另一台主机上面的私有仓库，最后用这个镜像生成一个数据容器挂载到应用容器上就好了。 备份数据卷docker run --rm --volumes-from data-container-backup --name tmp-backup -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /folderToBackup #Example: Backup mysql database docker run --rm --volumes-from blog-mysql --name tmp-backup -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /var/lib/mysql --rm 用来创建一个“用完即销”的容器，--volumes-from 用来把一个已有容器上挂载的卷挂载到新创建的容器上 创建数据容器docker run -d -v $(pwd):/backup --name data-backup alpine /bin/sh -c &quot;cd / &amp;&amp; tar xvf /backup/backup.tar&quot; 推送数据容器到私有仓库docker commit data-backup registry-host:port/data-backup:$VERSION docker push registry-host:port/data-backup:$VERSION 在另一台主机下载数据容器docker run -v /folderToBackup --entrypoint &quot;bin/sh&quot; --name data-container registry-host:port/data-backup:${VERSION} 将数据容器里面的数据卷挂载到应用容器上docker run --volumes-from=data-container registry-host:port/data-backup:${VERSION} # Example docker run --name new-mysql -d -p 3306:3306 --volumes-from=data-container registry-host:port/data-backup:${VERSION} 就这样 5 步操作，就可以很方便的备份、迁移数据库了。所以买主机也一定要买支持 Docker 的 KVM 虚拟机啊。 结以上","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://54skyray.cn/tags/docker/"},{"name":"mysql","slug":"mysql","permalink":"http://54skyray.cn/tags/mysql/"}]},{"title":"SSH超时排查,原来是这个问题","slug":"SSH超时排查，原来是这个问题","date":"2018-07-08T09:46:23.000Z","updated":"2019-12-06T07:53:36.625Z","comments":true,"path":"2018/07/08/SSH超时排查，原来是这个问题/","link":"","permalink":"http://54skyray.cn/2018/07/08/SSH超时排查，原来是这个问题/","excerpt":"前言最近在本地ssh远程服务经常性超时，正好有空索性就百度。找到这个解决办法，最终更改了MTU探测值得以解决，记录一下解决过程.","text":"前言最近在本地ssh远程服务经常性超时，正好有空索性就百度。找到这个解决办法，最终更改了MTU探测值得以解决，记录一下解决过程. 正文尝试首先我测试了一下 ping 远程服务器，发现结果还是比较正常的，所以在 icmp 协议上，连接应该是没有问题的。然后安装tcping 软件包，测试 tcp 连接，结果显示也是正常的，那么看起来就是 ssh 协议的问题了。于是接着尝试让 ssh 输出调试信息： $ ssh -v -o ConnectTimeout=10 test-server 输出结果如下: # ..... debug1: SSH2_MSG_KEXINIT sent debug1: SSH2_MSG_KEXINIT received debug1: kex: algorithm: curve25519-sha256 debug1: kex: host key algorithm: ecdsa-sha2-nistp256 debug1: kex: server-&gt;client cipher: chacha20-poly1305@openssh.com MAC: &lt;implicit&gt; compression: none debug1: kex: client-&gt;server cipher: chacha20-poly1305@openssh.com MAC: &lt;implicit&gt; compression: none debug1: expecting SSH2_MSG_KEX_ECDH_REPLY # 一直等待，直到超时 可以看到，ssh 连接的建立一直阻塞在了 expecting 这个阶段，用这行命令的输出在网络上查找，发现了是 MTU 过大引起的问题： mtu missmatch。这片文章给出的解决方案是将系统的 MTU 的设置成一个较小的值（例如，576）。使用 ip 命令简单的执行了一下，发现确实可以解决 ssh 超时的问题： 查看当前的 MTU 设置 $ ip link list 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: wlp4s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DORMANT group default qlen 1000 link/ether ac:bc:32:d4:cd:af brd ff:ff:ff:ff:ff:ff 解决修改无线网卡的 MTU 设置： $ sudo ip link set dev wlp4s0 mtu 576 但是我的潜意识告诉我这么干并不优雅，于是我在 Arch Wiki 上面找到了这个内容。这里面提到一个内核参数 —— tcp_mtu_probing，启用这项内核功能可以让操作系统根据网络状况自动的调节 MTU 大小，从而在性能与稳定性之间找到一个微妙的平衡，具体的介绍可以看 Cloudflare 这篇介绍 只要先在/etc/sysctl.d/99-sysctl.conf加上下面的内容： net.ipv4.tcp_mtu_probing = 1然后使用 sysctl加载配置就好了： $ sudo sysctl –system 结该文转自JaZhu 以上。","categories":[],"tags":[{"name":"ssh","slug":"ssh","permalink":"http://54skyray.cn/tags/ssh/"}]},{"title":"常见面试题之ConcurrentHashMap，聊聊1.7、1.8在实现上的差异","slug":"常见面试题之ConcurrentHashMap，聊聊1.7、1.8在实现上的差异","date":"2018-06-08T09:46:23.000Z","updated":"2019-04-12T08:17:48.232Z","comments":true,"path":"2018/06/08/常见面试题之ConcurrentHashMap，聊聊1.7、1.8在实现上的差异/","link":"","permalink":"http://54skyray.cn/2018/06/08/常见面试题之ConcurrentHashMap，聊聊1.7、1.8在实现上的差异/","excerpt":"前言在多线程环境下，使用HashMap进行put操作时存在丢失数据的情况，为了避免这种bug的隐患，强烈建议使用ConcurrentHashMap代替HashMap，为了对ConcurrentHashMap有更深入的了解，本文将对ConcurrentHashMap1.7和1.8的不同实现进行分析。","text":"前言在多线程环境下，使用HashMap进行put操作时存在丢失数据的情况，为了避免这种bug的隐患，强烈建议使用ConcurrentHashMap代替HashMap，为了对ConcurrentHashMap有更深入的了解，本文将对ConcurrentHashMap1.7和1.8的不同实现进行分析。 正文1.7实现数据结构 jdk1.7中采用Segment + HashEntry的方式进行实现，结构如图 ConcurrentHashMap初始化时，计算出Segment数组的大小ssize和每个Segment中HashEntry数组的大小cap，并初始化Segment数组的第一个元素；其中ssize大小为2的幂次方，默认为16，cap大小也是2的幂次方，最小值为2，最终结果根据根据初始化容量initialCapacity进行计算，计算过程如下：12345if (c * ssize &lt; initialCapacity) ++c;int cap = MIN_SEGMENT_TABLE_CAPACITY;while (cap &lt; c) cap &lt;&lt;= 1; 其中Segment在实现上继承了ReentrantLock，这样就自带了锁的功能。 put实现当执行put方法插入数据时，根据key的hash值，在Segment数组中找到相应的位置，如果相应位置的Segment还未初始化，则通过CAS进行赋值，接着执行Segment对象的put方法通过加锁机制插入数据，实现如下： 场景：线程A和线程B同时执行相同Segment对象的put方法 线程A执行tryLock()方法成功获取锁，则把HashEntry对象插入到相应的位置； 线程B获取锁失败，则执行scanAndLockForPut()方法，在scanAndLockForPut方法中，会通过重复执行tryLock()方法尝试获取锁，在多处理器环境下，重复次数为64，单处理器重复次数为1，当执行tryLock()方法的次数超过上限时，则执行lock()方法挂起线程B； 当线程A执行完插入操作时，会通过unlock()方法释放锁，接着唤醒线程B继续执行； size实现因为ConcurrentHashMap是可以并发插入数据的，所以在准确计算元素时存在一定的难度，一般的思路是统计每个Segment对象中的元素个数，然后进行累加，但是这种方式计算出来的结果并不一样的准确的，因为在计算后面几个Segment的元素个数时，已经计算过的Segment同时可能有数据的插入或则删除，在1.7的实现中，采用了如下方式：12345678910111213141516171819202122232425262728try &#123; for (;;) &#123; if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125;&#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125;&#125; 先采用不加锁的方式，连续计算元素的个数，最多计算3次： 如果前后两次计算结果相同，则说明计算出来的元素个数是准确的； 如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数； 1.8实现数据结构 1.8中放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，结构如下： 只有在执行第一次put方法时才会调用initTable()初始化Node数组，实现如下： 12345678910111213141516171819202122private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; put实现 当执行put方法插入数据时，根据key的hash值，在Node数组中找到相应的位置，实现如下： 如果相应位置的Node还未初始化，则通过CAS插入相应的数据； 1234else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin&#125; 如果相应位置的Node不为空，且当前该节点不处于移动状态，则对该节点加synchronized锁，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点； 12345678910111213141516171819if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125;&#125; 如果该节点是TreeBin类型的节点，说明是红黑树结构，则通过putTreeVal方法往红黑树中插入节点； 123456789else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125;&#125; 如果binCount不为0，说明put操作对数据产生了影响，如果当前链表的个数达到8个，则通过treeifyBin方法转化为红黑树，如果oldVal不为空，说明是一次更新操作，没有对元素个数产生影响，则直接返回旧值； 1234567if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break;&#125; 如果插入的是一个新节点，则执行addCount()方法尝试更新元素个数baseCount； size实现 1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount，实现如下： 123456789101112131415if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount();&#125; 初始化时counterCells为空，在并发量很高时，如果存在两个线程同时执行CAS修改baseCount值，则失败的线程会继续执行方法体中的逻辑，使用CounterCell记录元素个数的变化； 如果CounterCell数组counterCells为空，调用fullAddCount()方法进行初始化，并插入对应的记录数，通过CAS设置cellsBusy字段，只有设置成功的线程才能初始化CounterCell数组，实现如下： 12345678910111213141516else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean init = false; try &#123; // Initialize table if (counterCells == as) &#123; CounterCell[] rs = new CounterCell[2]; rs[h &amp; 1] = new CounterCell(x); counterCells = rs; init = true; &#125; &#125; finally &#123; cellsBusy = 0; &#125; if (init) break;&#125; 如果通过CAS设置cellsBusy字段失败的话，则继续尝试通过CAS修改baseCount字段，如果修改baseCount字段成功的话，就退出循环，否则继续循环插入CounterCell对象； 12else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; 所以在1.8中的size实现比1.7简单多，因为元素个数保存baseCount中，部分元素的变化个数保存在CounterCell数组中，实现如下：123456789101112131415161718public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125; final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 通过累加baseCount和CounterCell数组中的数量，即可得到元素的总个数 结文中阐述不妥之处还望雅正，不吝感激。 转载请注明出处:天雷 以上。","categories":[],"tags":[{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"http://54skyray.cn/tags/ConcurrentHashMap/"}]},{"title":"Java设计模式之策略模式-奇思妙想应用场景举例","slug":"Java设计模式之策略模式-奇思妙想应用场景举例","date":"2018-04-01T13:21:09.000Z","updated":"2018-09-02T09:13:10.936Z","comments":true,"path":"2018/04/01/Java设计模式之策略模式-奇思妙想应用场景举例/","link":"","permalink":"http://54skyray.cn/2018/04/01/Java设计模式之策略模式-奇思妙想应用场景举例/","excerpt":"前言本文将用诸葛亮搞得周瑜陪了夫人又折兵的三个锦囊妙计，来演示策略模式.","text":"前言本文将用诸葛亮搞得周瑜陪了夫人又折兵的三个锦囊妙计，来演示策略模式. 正文简介什么是策略模式策略模式，又叫算法簇模式，就是定义了不同的算法族，并且之间可以互相替换，此模式让算法的变化独立于使用算法的客户。 策略模式有什么好处策略模式的好处在于你可以动态的改变对象的行为。 设计原则 设计原则是把一个类中经常改变或者将来可能改变的部分提取出来，作为一个接口（c++z中可以用虚类），然后在类中包含这个对象的实例，这样类的实例在运行时就可以随意调用实现了这个接口的类的行为。下面是一个例子。 策略模式属于对象行为型模式，主要针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响 到客户端的情况下发生变化。通常，策略模式适用于当一个应用程序需要实现一种特定的服务或者功能，而且该程序有多种实现方式时使用。 策略模式中的三个对象 环境对象：该类中实现了对抽象策略中定义的接口或者抽象类的引用。 抽象策略对象：它可由接口或抽象类来实现。 具体策略对象：它封装了实现同不功能的不同算法。 利用策略模式构建应用程序，可以根据用户配置等内容，选择不同有算法来实现应用程序的功能。具体的选择有环境对象来完成。采用这种方式可以避免由于使用条件语句而带来的代码混乱，提高应用程序的灵活性与条理性。 应用场景举例刘备要到江东娶老婆了，走之前诸葛亮给赵云（伴郎）三个锦囊妙计，说是按天机拆开能解决棘手问题，嘿，还别说，真解决了大问题，搞到最后是周瑜陪了夫人又折兵，那咱们先看看这个场景是什么样子的。 先说说这个场景中的要素：三个妙计，一个锦囊，一个赵云，妙计是亮哥给的，妙计放在锦囊里，俗称就是锦囊妙计嘛，那赵云就是一个干活的人，从锦囊取出妙计，执行，然后获胜。用java程序怎么表现这些呢？ 那我们先来看看图？ 三个妙计是同一类型的东西，那咱就写个接口： 1234567891011package com.yangguangfu.strategy;/** * * @author trygf521@126.com:阿福 * 首先定义一个策略接口，这是诸葛亮老人家给赵云的三个锦囊妙计的接口。 */public interface IStrategy &#123; //每个锦囊妙计都是一个可执行的算法。 public void operate();&#125; 然后再写三个实现类，有三个妙计嘛： 妙计一：初到吴国： 1234567891011121314package com.yangguangfu.strategy;/** * * @author trygf521@126.com:阿福 * 找乔国老帮忙，使孙权不能杀刘备。 */public class BackDoor implements IStrategy &#123; @Override public void operate() &#123; System.out.println(&quot;找乔国老帮忙，让吴国太给孙权施加压力，使孙权不能杀刘备...&quot;); &#125;&#125; 妙计二：求吴国太开个绿灯，放行： 123456789101112131415package com.yangguangfu.strategy;/** * * @author trygf521@126.com:阿福 * 求吴国太开个绿灯。 */public class GivenGreenLight implements IStrategy &#123; @Override public void operate() &#123; System.out.println(&quot;求吴国太开个绿灯，放行！&quot;); &#125;&#125; 妙计三：孙夫人断后，挡住追兵： 123456789101112131415package com.yangguangfu.strategy;/** * * @author trygf521@126.com:阿福 * 孙夫人断后，挡住追兵。 */public class BlackEnemy implements IStrategy &#123; @Override public void operate() &#123; System.out.println(&quot;孙夫人断后，挡住追兵...&quot;); &#125;&#125; 好了，大家看看，三个妙计是有了，那需要有个地方放妙计啊，放锦囊里： 12345678910111213141516171819package com.yangguangfu.strategy;/** * * @author trygf521@126.com:阿福 * */public class Context &#123; private IStrategy strategy; //构造函数，要你使用哪个妙计 public Context(IStrategy strategy)&#123; this.strategy = strategy; &#125; public void operate()&#123; this.strategy.operate(); &#125;&#125; 然后就是赵云雄赳赳的揣着三个锦囊，拉着已步入老年行列，还想着娶纯情少女的，色咪咪的刘备老爷子去入赘了，嗨，还别说，亮哥的三个妙计还真不错，瞧瞧： 123456789101112131415161718192021222324252627282930package com.yangguangfu.strategy;public class ZhaoYun &#123; /** * 赵云出场了，他根据诸葛亮给他的交代，依次拆开妙计 */ public static void main(String[] args) &#123; Context context; //刚到吴国的时候拆开第一个 System.out.println(&quot;----------刚刚到吴国的时候拆开第一个---------------&quot;); context = new Context(new BackDoor()); context.operate();//拆开执行 System.out.println(&quot;\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n&quot;); //当刘备乐不思蜀时，拆开第二个 System.out.println(&quot;----------刘备乐不思蜀，拆第二个了---------------&quot;); context = new Context(new GivenGreenLight()); context.operate();//拆开执行 System.out.println(&quot;\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n&quot;); //孙权的小追兵了，咋办？拆开第三个锦囊 System.out.println(&quot;----------孙权的小追兵了，咋办？拆开第三个锦囊---------------&quot;); context = new Context(new BlackEnemy()); context.operate();//拆开执行 System.out.println(&quot;\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n&quot;); &#125;&#125; 结如有诠释不清或说错的地方请不吝指正，与大家一起成长 转载请注明出处:天雷 以上 参考资料 阿福","categories":[],"tags":[{"name":"Java设计模式","slug":"Java设计模式","permalink":"http://54skyray.cn/tags/Java设计模式/"}]},{"title":"Java设计模式之代理模式-奇思妙想应用场景举例","slug":"Java设计模式之代理模式-奇思妙想应用场景举例","date":"2018-03-19T12:21:09.000Z","updated":"2018-09-02T09:09:48.750Z","comments":true,"path":"2018/03/19/Java设计模式之代理模式-奇思妙想应用场景举例/","link":"","permalink":"http://54skyray.cn/2018/03/19/Java设计模式之代理模式-奇思妙想应用场景举例/","excerpt":"前言本文将用西门庆、潘金莲、王婆等人来解释静态代理模式。再继续延伸动态代理模式。","text":"前言本文将用西门庆、潘金莲、王婆等人来解释静态代理模式。再继续延伸动态代理模式。 正文静态代理模式什么是代理模式？代理模式的作用是：为其他对象提供一种代理以控制对这个对象的访问。 代理模式有什么好处？在某些情况下，一个客户不想或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。 代理模式一般涉及到的角色有： 抽象角色：声明真实对象和代理对象的共同接口； 代理角色：代理对象角色内部含有对真实对象的引用，从而可以操作真实对象，同时代理对象提供与真实对象相同的接口以便在任何时刻都能代替真实对象。同时，代理对象可以在执行真实对象操作时，附加其他的操作，相当于对真实对象进行封装。 真实角色：代理角色所代表的真实对象，是我们最终要引用的对象。 应用场景举例：比如西门庆找潘金莲，那潘金莲不好意思答复呀，咋办，找那个王婆做代理，表现在程序上时是这样的体现的 先说说这个场景中的要素：一种类型的女人，潘金莲，王婆，西门庆，后来扩展的贾氏也和西门庆勾上了，我们是假设的，然后西门庆找潘金莲happy,但潘金莲不好意思直接，就找个王婆代理呗。我们看看具体代码。 先定义一种女人 1234567891011121314package com.yangguangfu.proxy; /** * * @author 阿福(trygf521@126.com)&lt;br&gt; *定义一种类型的女人，王婆和潘金莲都属于这个类型的女人 */ public interface KindWoman &#123; //这种女人能做什么事情呢？ public void makeEyesWithMan();//抛媚眼 public void happyWithMan();//和男人那个.... &#125; 一种类型嘛，那肯定是接口，定义个潘金莲 1234567891011121314151617181920package com.yangguangfu.proxy;/** * * @author 阿福(trygf521@126.com)&lt;br&gt; *定义一个潘金莲是什么样的人 */public class PanJinLian implements KindWoman&#123; @Override public void happyWithMan() &#123; System.out.println(&quot;潘金莲和男人在做那个...&quot;); &#125; @Override public void makeEyesWithMan() &#123; System.out.println(&quot;潘金莲抛媚眼...&quot;); &#125;&#125; 再定义个丑陋的王婆 1234567891011121314151617181920212223242526272829303132333435package com.yangguangfu.proxy;/** * * @author 阿福(trygf521@126.com)&lt;br&gt; *王婆这个人老聪明了，她太老了，是个男人都看不上她， *但是她有智慧经验呀，他作为一类女人的代理！ */public class WangPo implements KindWoman &#123; private KindWoman kindWoman; public WangPo()&#123; //默认的话是潘金莲的代理 this.kindWoman = new PanJinLian(); &#125; //她可以是KindWomam的任何一个女人的代理，只要你是这一类型 public WangPo(KindWoman kindWoman)&#123; this.kindWoman = kindWoman; &#125; @Override public void happyWithMan() &#123; //自己老了，干不了了，但可以叫年轻的代替。 this.kindWoman.happyWithMan(); &#125; @Override public void makeEyesWithMan() &#123; //王婆年纪大了，谁看她抛媚眼啊 this.kindWoman.makeEyesWithMan(); &#125;&#125; 两个女主角都上场了，该男主角了，定义个西门庆 1234567891011121314151617181920212223242526package com.yangguangfu.proxy;/** * * @author 阿福(trygf521@126.com)&lt;br&gt; *水浒传是这样写的：西门庆被潘金莲用竹竿敲了一下，西门庆看痴迷了，被王婆看到了，就开始撮合两人好事，王婆作为潘金莲的代理人收了不少好处费，那我们假设一下： *如果没有王婆在中间牵线，这两个不要脸的能成事吗？难说得很！ */public class XiMenQiang &#123; /** * @param args */ public static void main(String[] args) &#123; WangPo wangPo; //把王婆叫出来 wangPo = new WangPo(); //然后西门庆说，我要和潘金莲Happy,然后王婆就安排了西门庆丢筷子哪出戏： wangPo.makeEyesWithMan(); //看到没有表面是王婆在做，其实爽的是潘金莲 wangPo.happyWithMan(); &#125;&#125; 那这就是活生生的一个例子，通过代理人实现了某种目的，如果真去了王婆这个中间环节，直接西门庆和潘金莲勾搭，估计很难成就武松杀嫂事件。那我们再考虑一下，水浒里面还有没有这类型的女人？有，卢俊义的老婆贾氏（就是和那个管家苟合的那个），这个名字起的：“贾氏”，那我们也让王婆做她的代理： 12345678910111213141516171819202122package com.yangguangfu.proxy;/** * * @author 阿福(trygf521@126.com)&lt;br&gt; *定义一个贾氏是什么样的人 */public class JiaShi implements KindWoman &#123; @Override public void happyWithMan() &#123; System.out.println(&quot;贾氏和男人在做那个...&quot;); &#125; @Override public void makeEyesWithMan() &#123; System.out.println(&quot;贾氏抛媚眼...&quot;); &#125;&#125; 西门庆勾潘金莲又勾引贾氏 1234567891011121314151617181920212223242526272829303132package com.yangguangfu.proxy;/** * * @author 阿福(trygf521@126.com)&lt;br&gt; *水浒传是这样写的：西门庆被潘金莲用竹竿敲了一下，西门庆看痴迷了，被王婆看到了，就开始撮合两人好事，王婆作为潘金莲的代理人收了不少好处费，那我们假设一下： *如果没有王婆在中间牵线，这两个不要脸的能成事吗？难说得很！ */public class XiMenQiang &#123; /** * @param args */ public static void main(String[] args) &#123; WangPo wangPo; //把王婆叫出来 wangPo = new WangPo(); //然后西门庆说，我要和潘金莲Happy,然后王婆就安排了西门庆丢筷子哪出戏： wangPo.makeEyesWithMan(); //看到没有表面是王婆在做，其实爽的是潘金莲 wangPo.happyWithMan(); //西门庆勾引贾氏 JiaShi jiaShi = new JiaShi(); wangPo = new WangPo(jiaShi); wangPo.makeEyesWithMan(); wangPo.happyWithMan(); &#125;&#125; 总结代理模式主要使用了java的多态，干活的是被代理类，代理类主要是接活，你让我干活，好，我交给幕后的类去干 动态代理模式简要说明动态代理，代理类并不是在Java代码中定义的，而是在运行时根据我们在Java代码中的“指示”动态生成的。相比于静态代理， 动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。假如我想在每个代理的方法前都加上一个处理方法:12345public void giveMoney() &#123; //调用被代理方法前加入处理方法 beforeMethod(); stu.giveMoney(); &#125; 动态的简单实现在java的java.lang.reflect包下提供了一个Proxy类和一个InvocationHandler接口，通过这个类和这个接口可以生成JDK动态代理类和动态代理对象。 创建一个动态代理对象的步骤，具体代码见后面: 创建一个InvocationHandler对象 12//创建一个与代理对象相关联的InvocationHandler InvocationHandler stuHandler = new MyInvocationHandler&lt;Person&gt;(stu); 使用Proxy类的getProxyClass静态方法生成一个动态代理类stuProxyClass 1Class&lt;?&gt; stuProxyClass = Proxy.getProxyClass(Person.class.getClassLoader(), new Class&lt;?&gt;[] &#123;Person.class&#125;); 获得stuProxyClass 中一个带InvocationHandler参数的构造器constructor 1Constructor&lt;?&gt; constructor = PersonProxy.getConstructor(InvocationHandler.class); 通过构造器constructor来创建一个动态实例stuProxy 1Person stuProxy = (Person) cons.newInstance(stuHandler); 就此，一个动态代理对象就创建完毕，当然，上面四个步骤可以通过Proxy类的newProxyInstances方法来简化： 1234 //创建一个与代理对象相关联的InvocationHandler InvocationHandler stuHandler = new MyInvocationHandler&lt;Person&gt;(stu);//创建一个代理对象stuProxy，代理对象的每个执行方法都会替换执行Invocation中的invoke方法 Person stuProxy= (Person) Proxy.newProxyInstance(Person.class.getClassLoader(), new Class&lt;?&gt;[]&#123;Person.class&#125;, stuHandler); 到这里肯定都会很疑惑，这动态代理到底是如何执行的，是如何通过代理对象来执行被代理对象的方法的，先不急，我们先看看一个简单的完整的动态代理的例子。还是上面静态代理的例子，班长需要帮学生代交班费。 首先是定义一个Person接口: 12345678/** * 创建Person接口 * @author Gonjan */public interface Person &#123; //上交班费 void giveMoney();&#125; 创建需要被代理的实际类： 1234567891011121314151617public class Student implements Person &#123; private String name; public Student(String name) &#123; this.name = name; &#125; @Override public void giveMoney() &#123; try &#123; //假设数钱花了一秒时间 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name + &quot;上交班费50元&quot;); &#125;&#125; 再定义一个检测方法执行时间的工具类，在任何方法执行前先调用start方法，执行后调用finsh方法，就可以计算出该方法的运行时间，这也是一个最简单的方法执行时间检测工具。 1234567891011121314public class MonitorUtil &#123; private static ThreadLocal&lt;Long&gt; tl = new ThreadLocal&lt;&gt;(); public static void start() &#123; tl.set(System.currentTimeMillis()); &#125; //结束时打印耗时 public static void finish(String methodName) &#123; long finishTime = System.currentTimeMillis(); System.out.println(methodName + &quot;方法耗时&quot; + (finishTime - tl.get()) + &quot;ms&quot;); &#125;&#125; 创建StuInvocationHandler类，实现InvocationHandler接口，这个类中持有一个被代理对象的实例target。InvocationHandler中有一个invoke方法，所有执行代理对象的方法都会被替换成执行invoke方法。 再再invoke方法中执行被代理对象target的相应方法。当然，在代理过程中，我们在真正执行被代理对象的方法前加入自己其他处理。这也是Spring中的AOP实现的主要原理，这里还涉及到一个很重要的关于java反射方面的基础知识。 123456789101112131415161718192021222324public class StuInvocationHandler&lt;T&gt; implements InvocationHandler &#123; //invocationHandler持有的被代理对象 T target; public StuInvocationHandler(T target) &#123; this.target = target; &#125; /** * proxy:代表动态代理对象 * method：代表正在执行的方法 * args：代表调用目标方法时传入的实参 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;代理执行&quot; +method.getName() + &quot;方法&quot;); */ //代理过程中插入监测方法,计算该方法耗时 MonitorUtil.start(); Object result = method.invoke(target, args); MonitorUtil.finish(method.getName()); return result; &#125;&#125; 做完上面的工作后，我们就可以具体来创建动态代理对象了，上面简单介绍了如何创建动态代理对象，我们使用简化的方式创建动态代理对象： 12345678910111213141516public class ProxyTest &#123; public static void main(String[] args) &#123; //创建一个实例对象，这个对象是被代理的对象 Person zhangsan = new Student(&quot;张三&quot;); //创建一个与代理对象相关联的InvocationHandler InvocationHandler stuHandler = new StuInvocationHandler&lt;Person&gt;(zhangsan); //创建一个代理对象stuProxy来代理zhangsan，代理对象的每个执行方法都会替换执行Invocation中的invoke方法 Person stuProxy = (Person) Proxy.newProxyInstance(Person.class.getClassLoader(), new Class&lt;?&gt;[]&#123;Person.class&#125;, stuHandler)； //代理执行上交班费的方法 stuProxy.giveMoney(); &#125;&#125; 我们执行这个ProxyTest类，先想一下，我们创建了一个需要被代理的学生张三，将zhangsan对象传给了stuHandler中，我们在创建代理对象stuProxy时，将stuHandler作为参数了的，上面也有说到所有执行代理对象的方法都会被替换成执行invoke方法，也就是说，最后执行的是StuInvocationHandler中的invoke方法。所以在看到下面的运行结果也就理所当然了。 运行结果： 上面说到，动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。是因为所有被代理执行的方法，都是通过在InvocationHandler中的invoke方法调用的，所以我们只要在invoke方法中统一处理，就可以对所有被代理的方法进行相同的操作了。例如，这里的方法计时，所有的被代理对象执行的方法都会被计时，然而我只做了很少的代码量。 总结动态代理的过程，代理对象和被代理对象的关系不像静态代理那样一目了然，清晰明了。因为动态代理的过程中，我们并没有实际看到代理类，也没有很清晰地的看到代理类的具体样子，而且动态代理中被代理对象和代理对象是通过InvocationHandler来完成的代理过程的 结就这三招，搞得的周郎是“赔了夫人又折兵”呀！这就是策略模式，高内聚低耦合的特点也表现出来了，还有一个就是扩展性，也就是OCP原则，策略类可以继续添加下去气，只是修改Context.java就可以了，这个不多说了，自己领会吧。如有诠释不清或说错的地方请不吝指正，与大家一起成长 转载请注明出处:天雷 以上 参考资料 阿福","categories":[],"tags":[{"name":"Java设计模式","slug":"Java设计模式","permalink":"http://54skyray.cn/tags/Java设计模式/"}]},{"title":"数据库日常innoDB-最佳实践有其五，知其所以然","slug":"数据库日常innoDB-最佳实践有其五，知其所以然","date":"2018-03-08T09:55:23.000Z","updated":"2019-04-12T08:18:13.271Z","comments":true,"path":"2018/03/08/数据库日常innoDB-最佳实践有其五，知其所以然/","link":"","permalink":"http://54skyray.cn/2018/03/08/数据库日常innoDB-最佳实践有其五，知其所以然/","excerpt":"前言关系型数据库MySQL两个最常用的存储引擎,MyISAM和InnoDB。照自己的理解，把一些知识点总结出来，一些场景知道该用某种存储引擎，却不知道为什么，所以来讲讲。","text":"前言关系型数据库MySQL两个最常用的存储引擎,MyISAM和InnoDB。照自己的理解，把一些知识点总结出来，一些场景知道该用某种存储引擎，却不知道为什么，所以来讲讲。 正文关于count(*) 知识点：MyISAM会直接存储总行数，InnoDB则不会，需要按行扫描。 潜台词是，对于select count(*) from t; 如果数据量大，MyISAM会瞬间返回，而InnoDB则会一行行扫描。 实践：数据量大的表，InnoDB不要轻易select count(*)，性能消耗极大。 常见坑：只有查询全表的总行数，MyISAM才会直接返回结果，当加了where条件后，两种存储引擎的处理方式类似。 1234例如：t_user(uid, uname, age, sex);uid PKage index 12select count(*) where age&lt;18 and sex=&apos;F&apos;;查询未成年少女个数，两种存储引擎的处理方式类似，都需要进行索引扫描。 启示：不管哪种存储引擎，都要建立好索引。 关于全文索引 知识点：MyISAM支持全文索引，InnoDB5.6之前不支持全文索引。 实践：不管哪种存储引擎，在数据量大并发量大的情况下，都不应该使用数据库自带的全文索引，会导致小量请求占用大量数据库资源，而要使用《索引外置》的架构设计方法。 启示：大数据量+高并发量的业务场景，全文索引，MyISAM也不是最优之选。 关于事务 知识点：MyISAM不支持事务，InnoDB支持事务。 实践：事务是选择InnoDB非常诱人的原因之一，它提供了commit，rollback，崩溃修复等能力。在系统异常崩溃时，MyISAM有一定几率造成文件损坏，这是非常烦的。但是，事务也非常耗性能，会影响吞吐量，建议只对一致性要求较高的业务使用复杂事务。画外音：Can’t open file ‘XXX.MYI’. 碰到过么？ 小技巧：MyISAM可以通过lock table表锁，来实现类似于事务的东西，但对数据库性能影响较大，强烈不推荐使用。 关于外键 知识点：MyISAM不支持外键，InnoDB支持外键。 实践：不管哪种存储引擎，在数据量大并发量大的情况下，都不应该使用外键，而建议由应用程序保证完整性。 关于行锁与表锁 知识点：MyISAM只支持表锁，InnoDB可以支持行锁。 分析： MyISAM：执行读写SQL语句时，会对表加锁，所以数据量大，并发量高时，性能会急剧下降。 InnoDB：细粒度行锁，在数据量大，并发量高时，性能比较优异。 实践：网上常常说，select+insert的业务用MyISAM，因为MyISAM在文件尾部顺序增加记录速度极快。楼主的建议是，绝大部分业务是混合读写，只要数据量和并发量较大，一律使用InnoDB。 常见坑：InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁。画外音：Oracle的行锁实现机制不同。 12345678910111213例如：t_user(uid, uname, age, sex) innodb;uid PK无其他索引update t_user set age=10 where uid=1;命中索引，行锁。update t_user set age=10 where uid != 1;未命中索引，表锁。update t_user set age=10 where name=&apos;shenjian&apos;;无索引，表锁。 启示：InnoDB务必建好索引，否则锁粒度较大，会影响并发。 总结在大数据量，高并发量的互联网业务场景下，对于MyISAM和InnoDB 有where条件，count(*)两个存储引擎性能差不多 不要使用全文索引，应当使用《索引外置》的设计方案 事务影响性能，强一致性要求才使用事务 不用外键，由应用程序来保证完整性 不命中索引，InnoDB也不能用行锁 结在大数据量，高并发量的互联网业务场景下，请使用InnoDB: 行锁，对提高并发帮助很大 事务，对数据一致性帮助很大这两个点，是InnoDB最吸引人的地方。 文中阐述不妥之处还望雅正，不吝感激。 本文参考架构师之路 转载请注明出处:天雷 以上。","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://54skyray.cn/tags/数据库/"},{"name":"innoDB","slug":"innoDB","permalink":"http://54skyray.cn/tags/innoDB/"}]},{"title":"百度云2018限速破解,简直比超级会员还快","slug":"百度云2018限速破解-简直比超级会员还快","date":"2018-01-08T09:46:23.000Z","updated":"2019-04-12T08:17:34.529Z","comments":true,"path":"2018/01/08/百度云2018限速破解-简直比超级会员还快/","link":"","permalink":"http://54skyray.cn/2018/01/08/百度云2018限速破解-简直比超级会员还快/","excerpt":"前言亲身试验感觉很不错。推荐！","text":"前言亲身试验感觉很不错。推荐！ 正文软件目录如图: mac安装演示安装好 mac安装包-1.4.1.dmg后，启动即可 windows安装直接打开windows安装包，请无视360等杀毒软件 谷歌浏览器插件安装谷歌插件.crx打开浏览器 输入chrome://extensions/ ，然后打钩开发者模式，最后把谷歌插件.crx拖进来安装即可，下图就是拖进来安装好的界面。 谷歌浏览器安装完成后效果安装好了后，你用浏览器打开百度云盘，就会发现上面会出现高速下载按钮了。 选中你要下载的文件，然后点击高速下载，就会自动跑到刚才安装的downloader那边下载。 软件下载地址点击该微云链接 密码：7vtB9P (更新于08月20号) 结软件是转自嘟嘟，感谢 转载请注明出处:天雷 以上 软件来自 嘟嘟的博客","categories":[],"tags":[{"name":"精品软件推荐","slug":"精品软件推荐","permalink":"http://54skyray.cn/tags/精品软件推荐/"},{"name":"百度云","slug":"百度云","permalink":"http://54skyray.cn/tags/百度云/"}]},{"title":"JVM、GC和常用命令","slug":"JVM、GC和常用命令","date":"2018-01-08T02:32:18.000Z","updated":"2019-04-12T08:21:31.659Z","comments":true,"path":"2018/01/08/JVM、GC和常用命令/","link":"","permalink":"http://54skyray.cn/2018/01/08/JVM、GC和常用命令/","excerpt":"前言重新梳理了一遍JVM的一些基本概念和学习资料。在这个PPT中，关于G1的部分比较粗略","text":"前言重新梳理了一遍JVM的一些基本概念和学习资料。在这个PPT中，关于G1的部分比较粗略 正文 结该文转自https://www.jianshu.com/p/5121f917c3ce 以上。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://54skyray.cn/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://54skyray.cn/tags/JVM/"}]},{"title":"Hexo博客yilia使用Gitalk作评论插件","slug":"Hexo博客yilia使用Gitalk作评论插件","date":"2017-08-05T07:58:25.000Z","updated":"2019-04-12T08:18:38.584Z","comments":true,"path":"2017/08/05/Hexo博客yilia使用Gitalk作评论插件/","link":"","permalink":"http://54skyray.cn/2017/08/05/Hexo博客yilia使用Gitalk作评论插件/","excerpt":"前言作为一个技术类博客怎能面得了一个评论插件呢。多说挂了，本想跟随yilia的主人Litten使用畅言，无奈这厮居然要备案(这种一看就很麻烦的对我这种懒人，pass)。然后我就找了一个国人自制开源的插件:gitalk，挺小众我喜欢。网上没有找到yilia搭载该插件的相关教程，索性写一个，仅希望各位同仁少走弯路。","text":"前言作为一个技术类博客怎能面得了一个评论插件呢。多说挂了，本想跟随yilia的主人Litten使用畅言，无奈这厮居然要备案(这种一看就很麻烦的对我这种懒人，pass)。然后我就找了一个国人自制开源的插件:gitalk，挺小众我喜欢。网上没有找到yilia搭载该插件的相关教程，索性写一个，仅希望各位同仁少走弯路。 正文概述本文主要针对使用yilia的同学使用gitalk的一个小教程 特性 使用 Github 登录 支持多语言 [en, zh-CN, zh-TW, es-ES, fr] 支持个人或组织 无干扰模式（设置 distractionFreeMode 为 true 开启） 快捷键提交评论 （cmd|ctrl + enter） 在线实例 博客实例 安装(二选一)直接引入&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;!-- or --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; npm安装npm i --save gitalk import &apos;gitalk/dist/gitalk.css&apos; import Gitalk from &apos;gitalk&apos; 使用 因为我懒所以我选择第一种 新建仓库 Github上新建一个仓库，命名随便只要记得住，关于github建仓库，不懂的百度一大堆 创建OAuth Application，没有的小伙伴点击这里 完成后会生成相应的clientID and clientSecret。 修改主题文件1.不同的主题目录和模板引擎不同，可以自己修改。修改主题配置文件_config.yml,添加字段 # Gitalk gitalk: enable: true #是否启用 clientID: your clientId #上面生成的id clientSecret: your clientSecret #同上 repo: 你创建的仓库名称 owner: github的用户名(master权限) admin: github的用户名(master权限) distractionFreeMode: true 2.在主题目录yilia\\layout\\_partial\\post下创建文件gitalk.ejs 复制以下代码: &lt;div id=&quot;gitalk-container&quot; style=&quot;padding: 0px 30px 0px 46px;&quot;&gt;&lt;/div&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk({ clientID: &apos;&lt;%=theme.gitalk.clientID%&gt;&apos;, clientSecret: &apos;&lt;%=theme.gitalk.clientSecret&gt;&apos;, id: window.location.pathname, repo: &apos;&lt;%=theme.gitalk.repo%&gt;&apos;, owner: &apos;&lt;%=theme.gitalk.owner%&gt;&apos;, admin: &apos;&lt;%=theme.gitalk.admin%&gt;&apos;, distractionFreeMode: &apos;&lt;%=theme.gitalk.distractionFreeMode%&gt;&apos;, }) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt; 3.最后修改yilia\\layout\\_partial\\article.ejs文件,找到代码 &lt;% if (!index &amp;&amp; post.comments){ %&gt; 并在其后添加以下代码 &lt;% if (theme.gitalk.enable &amp;&amp; theme.gitalk.distractionFreeMode){ %&gt; &lt;%- partial(&apos;post/gitalk&apos;, { key: post.slug, title: post.title, url: config.url+url_for(post.path) }) %&gt; &lt;% } %&gt; 插件添加完成。 结移动端也可实现了 文中阐述不妥之处还望雅正，不吝感激。 转载请注明出处:天雷 以上。 参考文章Hexo添加Gitalk评论插件 from erbiduo","categories":[],"tags":[{"name":"yilia","slug":"yilia","permalink":"http://54skyray.cn/tags/yilia/"},{"name":"hexo","slug":"hexo","permalink":"http://54skyray.cn/tags/hexo/"},{"name":"Gitalk评论插件","slug":"Gitalk评论插件","permalink":"http://54skyray.cn/tags/Gitalk评论插件/"}]},{"title":"敏捷开发那么普及，你了解它吗?","slug":"敏捷开发那么普及，你了解它吗","date":"2017-06-04T11:47:29.000Z","updated":"2019-04-12T08:17:58.287Z","comments":true,"path":"2017/06/04/敏捷开发那么普及，你了解它吗/","link":"","permalink":"http://54skyray.cn/2017/06/04/敏捷开发那么普及，你了解它吗/","excerpt":"前言今天是码畜入职的第一天:包工头: 码畜！欢迎加入研发组。码畜: 大家好，请多多关照.包工头: 10点了，咱们按照惯例进行每日的Scrum!码畜悄悄问小明: 啥是Scrum啊?小明鼓着气不假思索的吼着说: 你连Scrum都不知道，你工作经验是不是假的!!码畜:MMP","text":"前言今天是码畜入职的第一天:包工头: 码畜！欢迎加入研发组。码畜: 大家好，请多多关照.包工头: 10点了，咱们按照惯例进行每日的Scrum!码畜悄悄问小明: 啥是Scrum啊?小明鼓着气不假思索的吼着说: 你连Scrum都不知道，你工作经验是不是假的!!码畜:MMP 正文概述 敏捷开发，就是把一个大项目分为多个相互联系，但也可独立运行的小项目，并分别完成，在此过程中软件一直处于可使用状态。–百度百科 本文只做敏捷开发的简单介绍，区分开传统的开发模式,更多的知识还建议各位看一下这本书《敏捷软件开发》。 小例子(区分传统模式)场景一： 沙县小吃老板娘: 大叔，吃点啥?码畜:我要宫保鸡丁、鱼香肉丝…一共十个菜(心里想:大叔?劳资才25)沙县小吃老板娘: 好的，稍等.…40分钟过去了码畜:老板娘，都半个多小时了，咋还不上菜沙县小吃老板娘: 不好意思啊，你点了10个菜，要再一会…沙县小吃老板娘: 久等了，你点的10道菜全部做好了，一起给你上来了，请慢用码畜： what fxxk? 你不会用敏捷上菜吗！ 总结下：现实我们是不会遇到这种餐馆，因为每一道菜都是独立，很容易单独完成并交付。但是项目研发就不一样啦。传统的开发流程采用瀑布式开发，从设计到编码，从测试到交付，每一个阶段都必须完全完成，才能进入下一阶段。如:场景二: 产品:以上就是项目的需求，你们大概多久能搞好？包工头：我们需要做系统设计、详细设计、编码、测试..总共算下来，要一年左右才能上线。产品:一年?Are You Kidding Me?市场可不等人!包工头:呃，我们尽量加班加点，或许10个月可以交付….产品: ….. 让我们看看敏捷开发!! 什么是敏捷开发？敏捷开发（Agile）是一种以人为核心、迭代、循序渐进的开发方法。 在敏捷开发中，软件项目的构建被切分成多个子项目，各个子项目的成果都经过测试，具备集成和可运行的特征。 简单地来说，敏捷开发并不追求前期完美的设计、完美编码，而是力求在很短的周期内开发出产品的核心功能，尽早发布出可用的版本。然后在后续的生产周期内，按照新需求不断迭代升级，完善产品。 这一切正如某人的名言：是谁这么厉害，提出了敏捷开发思想？是一位名叫Martin Fowler的美国大叔。 大叔不但是敏捷开发的创始人之一，还在面向对象开发、设计模式、UML建模领域做出了重要贡献。目前担任ThoughtWorks公司的首席科学家。 敏捷开发模式的分类敏捷开发的实现主要包括 SCRUM、XP（极限编程）、Crystal Methods、FDD（特性驱动开发）等等。其中SCRUM与XP最为流行。 同样是敏捷开发，XP极限编程 更侧重于实践，并力求把实践做到极限。这一实践可以是测试先行，也可以是结对编程等，关键要看具体的应用场景。 SCRUM则是一种开发流程框架，也可以说是一种套路。SCRUM框架中包含三个角色，三个工件，四个会议，听起来很复杂，其目的是为了有效地完成每一次迭代周期的工作。在这里我们重点讨论的是SCRUM。 SCRUM的工作流程学习Scrum之前，我们先要了解几个基本术语： Sprint：冲刺周期，通俗的讲就是实现一个“小目标”的周期。一般需要2-6周时间。 User Story：用户的外在业务需求。拿银行系统来举例的话，一个Story可以是用户的存款行为，或者是查询余额等等。也就是所谓的小目标本身。 Task：由User Story 拆分成的具体开发任务。 Backlog：需求列表，可以看成是小目标的清单。分为Sprint Backlog和Product Backlog。 Daily meeting：每天的站会，用于监控项目进度。有些公司直接称其为Scrum。 Sprint Review meeting: 冲刺评审会议，让团队成员们演示成果。 Sprint burn down：冲刺燃尽图，说白了就是记录当前周期的需求完成情况。 Rlease：开发周期完成，项目发布新的可用版本。 如上图所示，在项目启动之前，会由团队的产品负责人（Product owner）按照需求优先级来明确出一份Product Backlog，为项目做出整体排期。 随后在每一个小的迭代周期里，团队会根据计划（Sprint Plan Meeting）确定本周期的Sprint Backlog，再细化成一个个Task，分配给团队成员，进行具体开发工作。每一天，团队成员都会进行Daily meeting，根据情况更新自己的Task状态，整个团队更新Sprint burn down chart。 当这一周期的Sprint backlog全部完成，团队会进行Spring review meeting，也就是评审会议。一切顺利的话，会发布出这一版本的Release，并且进行Sprint回顾会议（Sprint Retrospective Meeting）。 那么，现实中的Scrum是什么样的情景呢？看看下面的照片就知道了： 当然，上图主要作用是提升逼格! 延伸敏捷开发与DevopsDevops是Development和Operations的合成词，其目标是要加强开发人员、测试人员、运维人员之间的沟通协调。如何实现这一目标呢？需要我们的项目做到持续集成、持续交付、持续部署。 时下流行的Jenkins、Bamboo，就是两款优秀的持续集成工具。而Docker容器则为Devops提供了强大而有效的统一环境。 关于Devops以及Docker，在以后的文章中会做出更详细的介绍。 结文中阐述不妥之处还望雅正，不吝感激。 转载请注明出处:天雷 以上","categories":[],"tags":[{"name":"敏捷开发","slug":"敏捷开发","permalink":"http://54skyray.cn/tags/敏捷开发/"}]},{"title":"MAVEN依赖冲突了，你可能不知道还有这招","slug":"MAVEN依赖冲突了，你可能不知道还有这招","date":"2017-02-19T09:21:09.000Z","updated":"2019-04-12T08:19:52.922Z","comments":true,"path":"2017/02/19/MAVEN依赖冲突了，你可能不知道还有这招/","link":"","permalink":"http://54skyray.cn/2017/02/19/MAVEN依赖冲突了，你可能不知道还有这招/","excerpt":"前言做过大型Maven项目的任何人都很清楚，模块与库之间的所有依赖关系有多么错综复杂，遇到冲突甚至能让你生无可恋。但是如果你使用的IDE工具是IntelliJ IDEA 10.以上的版本。有一种方便快捷的处理冲突的方法，容我细细道来.!","text":"前言做过大型Maven项目的任何人都很清楚，模块与库之间的所有依赖关系有多么错综复杂，遇到冲突甚至能让你生无可恋。但是如果你使用的IDE工具是IntelliJ IDEA 10.以上的版本。有一种方便快捷的处理冲突的方法，容我细细道来.! 正文功能介绍在idea中会对Maven依赖创建一个特殊的布局（按照Pom.xml文件中定义的顺序显示依赖关系）,其实在Eclipse中也有类似的功能(Maven依赖关系图)，像这样: 看上图我们很难理解一个节点与另一个节点的联系，所有具有不同版本的节点都被合并，没有可见的冲突。 IntelliJ IDEA按照pom.xml定义的顺序显示依赖关系布局,在图表上很容易找到你的模块-它们是蓝色的，而测试依赖是绿色的。冲突的依赖关系被标记为红色，你可以选择其中一个来找到与之冲突的内容: 你可以通过排除依赖来修复冲突，IntelliJ IDEA提供所有可以添加排除定义的地方： 从节点到POM文件的导航也很方便,每个依赖关系直接链接到它所在的地方: 庞大的系统依赖关系错综复杂，咱们可以使用范围过滤器来减少节点数量: 功能要求Maven Dependencies Diagram将在IntelliJ IDEA 10以上版本搭载 操作演示这里以Idea 2017.1.1给各位操作演示一下 1.导入Maven项目到idea之后,并且运行Maven--Reimport就能在idea窗口右侧看到如下图标签 2.点开后对想要操作的项目点击右键能看到show Dependencies..如下图 3.弹出图表可以看到冲突的依赖有红线，冲突的可能性多种多样 4.对被标记红线的依赖右键看到Exclude,如重复依赖的话该依赖会被删除 基本操作完毕。。。简直就是手把手了 结转载请注明出处:天雷 以上 参考资料 IntelliJ IDEA官方博客","categories":[],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://54skyray.cn/tags/Maven/"},{"name":"Maven Dependecies","slug":"Maven-Dependecies","permalink":"http://54skyray.cn/tags/Maven-Dependecies/"},{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","permalink":"http://54skyray.cn/tags/IntelliJ-IDEA/"}]},{"title":"RabbitMQ基础概念简要介绍","slug":"RabbitMQ基础概念简要介绍","date":"2017-01-07T12:11:41.000Z","updated":"2019-04-12T08:17:04.039Z","comments":true,"path":"2017/01/07/RabbitMQ基础概念简要介绍/","link":"","permalink":"http://54skyray.cn/2017/01/07/RabbitMQ基础概念简要介绍/","excerpt":"前言微服务日常业务操作中不乏需要多个服务数据交互、多个服务异同步业务处理。一般都会选择消息服务中间件去解决这些操作。消息服务擅长于解决多系统、异构系统间的数据交换（消息通知/通讯）问题，你也可以把它用于系统间服务的相互调用（RPC）。本文将要介绍的RabbitMQ就是当前最主流的消息中间件之一。","text":"前言微服务日常业务操作中不乏需要多个服务数据交互、多个服务异同步业务处理。一般都会选择消息服务中间件去解决这些操作。消息服务擅长于解决多系统、异构系统间的数据交换（消息通知/通讯）问题，你也可以把它用于系统间服务的相互调用（RPC）。本文将要介绍的RabbitMQ就是当前最主流的消息中间件之一。 正文RabbitMQ简介AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 下面将重点介绍RabbitMQ中的一些基础概念，了解了这些概念，是使用好RabbitMQ的基础。 ConnectionFactory、Connection、ChannelConnectionFactory、Connection、Channel都是RabbitMQ对外提供的API中最基本的对象。Connection是RabbitMQ的socket链接，它封装了socket协议相关部分逻辑。ConnectionFactory为Connection的制造工厂。Channel是我们与RabbitMQ打交道的最重要的一个接口，我们大部分的业务操作是在Channel这个接口中完成的，包括定义Queue、定义Exchange、绑定Queue与Exchange、发布消息等。 QueueQueue（队列）是RabbitMQ的内部对象，用于存储消息，用下图表示。 RabbitMQ中的消息都只能存储在Queue中，生产者（下图中的P）生产消息并最终投递到Queue中，消费者（下图中的C）可以从Queue中获取消息并消费。 多个消费者可以订阅同一个Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。 Message acknowledgment在实际应用中，可能会发生消费者收到Queue中的消息，但没有处理完成就宕机（或出现其他意外）的情况，这种情况下就可能会导致消息丢失。为了避免这种情况发生，我们可以要求消费者在消费完消息后发送一个回执给RabbitMQ，RabbitMQ收到消息回执（Message acknowledgment）后才将该消息从Queue中移除；如果RabbitMQ没有收到回执并检测到消费者的RabbitMQ连接断开，则RabbitMQ会将该消息发送给其他消费者（如果存在多个消费者）进行处理。这里不存在timeout概念，一个消费者处理消息时间再长也不会导致该消息被发送给其他消费者，除非它的RabbitMQ连接断开。这里会产生另外一个问题，如果我们的开发人员在处理完业务逻辑后，忘记发送回执给RabbitMQ，这将会导致严重的bug——Queue中堆积的消息会越来越多；消费者重启后会重复消费这些消息并重复执行业务逻辑… 另外pub message是没有ack的。 Message durability如果我们希望即使在RabbitMQ服务重启的情况下，也不会丢失消息，我们可以将Queue与Message都设置为可持久化的（durable），这样可以保证绝大部分情况下我们的RabbitMQ消息不会丢失。但依然解决不了小概率丢失事件的发生（比如RabbitMQ服务器已经接收到生产者的消息，但还没来得及持久化该消息时RabbitMQ服务器就断电了），如果我们需要对这种小概率事件也要管理起来，那么我们要用到事务。由于这里仅为RabbitMQ的简单介绍，所以这里将不讲解RabbitMQ相关的事务。 Prefetch count前面我们讲到如果有多个消费者同时订阅同一个Queue中的消息，Queue中的消息会被平摊给多个消费者。这时如果每个消息的处理时间不同，就有可能会导致某些消费者一直在忙，而另外一些消费者很快就处理完手头工作并一直空闲的情况。我们可以通过设置prefetchCount来限制Queue每次发送给每个消费者的消息数，比如我们设置prefetchCount=1，则Queue每次给每个消费者发送一条消息；消费者处理完这条消息后Queue会再给该消费者发送一条消息。 Exchange在上一节我们看到生产者将消息投递到Queue中，实际上这在RabbitMQ中这种事情永远都不会发生。实际的情况是，生产者将消息发送到Exchange（交换器，下图中的X），由Exchange将消息路由到一个或多个Queue中（或者丢弃）。 Exchange是按照什么逻辑将消息路由到Queue的？这个将在Binding一节介绍。RabbitMQ中的Exchange有四种类型，不同的类型有着不同的路由策略，这将在Exchange Types一节介绍。 routing key生产者在将消息发送给Exchange的时候，一般会指定一个routing key，来指定这个消息的路由规则，而这个routing key需要与Exchange Type及binding key联合使用才能最终生效。在Exchange Type与binding key固定的情况下（在正常使用时一般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过指定routing key来决定消息流向哪里。RabbitMQ为routing key设定的长度限制为255 bytes。 BindingRabbitMQ中通过Binding将Exchange与Queue关联起来，这样RabbitMQ就知道如何正确地将消息路由到指定的Queue了。 Binding key在绑定（Binding）Exchange与Queue的同时，一般会指定一个binding key；消费者将消息发送给Exchange时，一般会指定一个routing key；当binding key与routing key相匹配时，消息将会被路由到对应的Queue中。这个将在Exchange Types章节会列举实际的例子加以说明。在绑定多个Queue到同一个Exchange的时候，这些Binding允许使用相同的binding key。binding key 并不是在所有情况下都生效，它依赖于Exchange Type，比如fanout类型的Exchange就会无视binding key，而是将消息路由到所有绑定到该Exchange的Queue。 Exchange TypesRabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种（AMQP规范里还提到两种Exchange Type，分别为system与自定义，这里不予以描述），下面分别进行介绍。 fanoutfanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。 上图中，生产者（P）发送到Exchange（X）的所有消息都会路由到图中的两个Queue，并最终被两个消费者（C1与C2）消费。 directdirect类型的Exchange路由规则也很简单，它会把消息路由到那些binding key与routing key完全匹配的Queue中。 以上图的配置为例，我们以routingKey=”error”发送消息到Exchange，则消息会路由到Queue1（amqp.gen-S9b…，这是由RabbitMQ自动生成的Queue名称）和Queue2（amqp.gen-Agl…）；如果我们以routingKey=”info”或routingKey=”warning”来发送消息，则消息只会路由到Queue2。如果我们以其他routingKey发送消息，则消息不会路由到这两个Queue中。 topic前面讲到direct类型的Exchange路由规则是完全匹配binding key与routing key，但这种严格的匹配方式在很多情况下不能满足实际业务需求。topic类型的Exchange在匹配规则上进行了扩展，它与direct类型的Exchage相似，也是将消息路由到binding key与routing key相匹配的Queue中，但这里的匹配规则有些不同，它约定： routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit” binding key与routing key一样也是句点号“. ”分隔的字符串 binding key中可以存在两种特殊字符“”与“#”，用于做模糊匹配，其中“”用于匹配一个单词，“#”用于匹配多个单词（可以是零个） 以上图中的配置为例，routingKey=”quick.orange.rabbit”的消息会同时路由到Q1与Q2，routingKey=”lazy.orange.fox”的消息会路由到Q1与Q2，routingKey=”lazy.brown.fox”的消息会路由到Q2，routingKey=”lazy.pink.rabbit”的消息会路由到Q2（只会投递给Q2一次，虽然这个routingKey与Q2的两个bindingKey都匹配）；routingKey=”quick.brown.fox”、routingKey=”orange”、routingKey=”quick.orange.male.rabbit”的消息将会被丢弃，因为它们没有匹配任何bindingKey。 headersheaders类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对；如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。该类型的Exchange没有用到过（不过也应该很有用武之地），所以不做介绍。 RPCMQ本身是基于异步的消息处理，前面的示例中所有的生产者（P）将消息发送到RabbitMQ后不会知道消费者（C）处理成功或者失败（甚至连有没有消费者来处理这条消息都不知道）。但实际的应用场景中，我们很可能需要一些同步处理，需要同步等待服务端将我的消息处理完成后再进行下一步处理。这相当于RPC（Remote Procedure Call，远程过程调用）。在RabbitMQ中也支持RPC。 RabbitMQ中实现RPC的机制是： 客户端发送请求（消息）时，在消息的属性（MessageProperties，在AMQP协议中定义了14中properties，这些属性会随着消息一起发送）中设置两个值replyTo（一个Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queu和-correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败） 服务器端收到消息并处理 服务器端处理完消息后，将生成一条应答消息到replyTo指定的Queue，同时带上correlationId属性 客户端之前已订阅replyTo指定的Queue，从中收到服务器的应答消息后，根据其中的correlationId属性分析哪条请求被执行了，根据执行结果进行后续业务处理 结本文介绍了RabbitMQ中个人认为最重要的概念，充分利用RabbitMQ提供的这些功能就可以处理我们绝大部分的异步业务了。 文中阐述不妥之处还望雅正，不吝感激。 转载请注明出处:天雷 以上","categories":[],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://54skyray.cn/tags/RabbitMQ/"},{"name":"消息队列","slug":"消息队列","permalink":"http://54skyray.cn/tags/消息队列/"},{"name":"RPC","slug":"RPC","permalink":"http://54skyray.cn/tags/RPC/"}]},{"title":"SSL协议之数据加密过程详解","slug":"SSL协议之数据加密过程详解","date":"2016-08-15T03:20:18.000Z","updated":"2019-04-12T08:17:22.963Z","comments":true,"path":"2016/08/15/SSL协议之数据加密过程详解/","link":"","permalink":"http://54skyray.cn/2016/08/15/SSL协议之数据加密过程详解/","excerpt":"前言HTTPS的流行，SSL协议功不可没，这篇博文将带领各位了解加密、以及SSL微妙的加密原理.","text":"前言HTTPS的流行，SSL协议功不可没，这篇博文将带领各位了解加密、以及SSL微妙的加密原理. SSL只要你听过HTTPS，不可能没听过SSL协议吧，SSL协议是一种安全协议。对于互联网协议没有了解的童鞋可以参考博主另一篇博客：internet协议入门 HTTP+SSL = HTTPS HTTPS之所以安全就是因为加持了SSL这个外挂来对传输的数据进行加密，那么具体的加密方法又是什么呢？ 请听我娓娓道来。先看下面两个概念： 对称加密 非对称加密 你知道上面两个概念是什么意思么？😳 🤣OK，不管你懂不懂，我先用我的方式来给你解释下： 亲，你作过弊么？不要告诉我在你漫长的学生生涯里你没作过弊(那你的学生生涯得多枯燥)，作弊我们常用的方法是啥？(说把答案写在胳膊大腿纸条上的同学请你出去，谢谢🙂)当然是加密了！比如我出于人道主义，想要帮助小明同学作弊，首先考试前我们会约定好一个暗号来传递选择题的答案，摸头发——A，摸耳朵——B，咳嗽——C，跺脚——D，于是一个加密方法就诞生了，这个加密方法只有我和小明知道，老师虽然看我抓耳挠腮但他顶多把我当成神经病，并没有直接证据说我作弊。好，这种我和小明知道，别人不知道的加密方法就是一种对称加密算法,对称加密算法也是我们日常最常见的加密算法。这种算法🔑只有一把，加密解密都用同一把钥匙，一旦🔑泄露就全玩完了。 随时时代的进步，人们发现实际上加密和解密不用同一把🔑也是可以的，只要加密和解密的两把🔑存在某种关系就行了。 于是，层出不穷的非对称加密算法就被研究了出来，那么它基于什么样的道理呢？请严格记住下面这句话： 将a和b相乘得出乘积c很容易，但要是想要通过乘积c推导出a和b极难。即对一个大数进行因式分解极难 听不懂因式分解的童鞋先去面壁5分钟，这么多年数学白学了？甩给你维基百科链接，自行补课🙂：因式分解好的，我们继续，非对称加密算法就多了两个概念——公钥c和私钥b。 用法如下：公钥加密的密文只能用私钥解密，私钥加密的密文只能用公钥解密。 公钥我们可以随便公开，因为别人知道了公钥毫无用处，经过公钥加密后的密文只能通过私钥来解密。而想要通过公钥推导出a和b极难。但很明显的是，使用非对称加密效率不如对称加密，因为非对称加密需要有计算两个密钥的过程。 我们通过密码学中的两个典型的爱丽丝和鲍勃人物来解释这个非对称加密算法的过程： 客户端叫做爱丽丝，服务器叫做鲍勃。 爱丽丝： 鲍勃我要给你发送一段消息，把你的公钥给我吧；鲍勃： OK，这是我的公钥：234nkjdfdhjbg324*；爱丽丝：收到公钥，我给你发送的消息经过公钥加密之后是这样的：##@#@!$%(@;鲍勃：好的，收到了，亲，我来用我的私钥解密看下你真正要给我发送的内容； 上述过程就是一个非对称加密的过程，这个过程安全么？好像是很安全，即使查理(通信中的第三位参加者)截取了密文和公钥没有私钥还是没法得到明文。😂 可如果第三者查理发送给爱丽丝他自己的公钥，然后爱丽丝用查理给的公钥加密密文发送了出去，查理再通过自己的私钥解密，这不就泄露信息了么？我们需要想个办法让爱丽丝判断这个公钥到底是不是鲍勃发来的。 于是就有了数字证书的概念： 数字证书就是互联网通讯中标志通讯各方身份信息的一串数字，提供了一种在Internet上验证通信实体身份的方式，数字证书不是数字身份证，而是身份认证机构盖在数字身份证上的一个章或印（或者说加在数字身份证上的一个签名）。 😑上面官方的解释看起来就头大。其实它就是一段信息。 数字证书内容大体如下： 签发证书的机构 鲍勃的加密算法 鲍勃所使用的Hash算法 鲍勃的公钥 证书到期时间 等等 数字证书是由权威机构——CA机构统一来进行发行，我们绝对信任这个机构，至于CA机构的安全性…反正99.99%之下都是安全的。🕵 为了防止中间有人对证书内容进行更改，有了一个数字签名的概念，所谓的数字签名就是把以上所有的内容做一个Hash操作，得到一个固定长度然后再传给鲍勃。然而如果别人截取了这个证书然后更改内容，同时生成了新的Hash值那怎么办？处于这个考虑，CA机构在颁发这个证书的时候会用自己的私钥将Hash值加密，从而防止了数字证书被篡改。 好，我们来梳理下整个过程： 第一步：首先，当爱丽丝开启一个新的浏览器第一次去访问鲍勃的时候，会先让爱丽丝安装一个数字证书，这个数字证书里包含的主要信息就是CA机构的公钥。 第二步：鲍勃发送来了CA机构颁发给自己的数字证书，爱丽丝通过第一步中已经得到的公钥解密CA用私钥加密的Hash-a(这个过程就是非对称加密)，然后再用传递过来的HASH算法生成一个Hash-b，如果Hash-a === Hash-b就说明认证通过，确实是鲍勃发过来的。 如上，是整个数字证书的使用过程就是这样的。 多说一句，非对称加密实际应用的例子除了SSL还有很多，比如SSH、电子签名等； 如上提到的，非对称加密计算量很大，效率不如对称加密，我们打开网页最注重的是啥？是速度！是速度！是速度！🏃🏃🏃 这点SSL就玩的很巧妙了🤣，通信双方通过对称加密来加密密文，然后使用非对称加密的方式来传递对称加密所使用的密钥。这样效率和安全就都能保证了。 SSL协议的握手过程先用语言来阐述下： 第一步：爱丽丝给出支持SSL协议版本号，一个客户端随机数(Client random，请注意这是第一个随机数)，客户端支持的加密方法等信息；第二步：鲍勃收到信息后，确认双方使用的加密方法，并返回数字证书，一个服务器生成的随机数(Server random，注意这是第二个随机数)等信息；第三步：爱丽丝确认数字证书的有效性，然后生成一个新的随机数(Premaster secret)，然后使用数字证书中的公钥，加密这个随机数，发给鲍勃。第四步：鲍勃使用自己的私钥，获取爱丽丝发来的随机数(即Premaster secret)；(第三、四步就是非对称加密的过程了)第五步：爱丽丝和鲍勃通过约定的加密方法(通常是AES算法)，使用前面三个随机数，生成对话密钥，用来加密接下来的通信内容； 俗话说一图胜千言，我画了一个图来说明这个过程： OK，整个进行数据加密的过程结束。我们再来回忆下内容： CA机构颁发数字证书给鲍勃； 爱丽丝和鲍勃进行SSL握手，爱丽丝通过数字证书确定鲍勃的身份； 爱丽丝和鲍勃传递三个随机数，第三个随机数通过非对称加密算法进行传递； 爱丽丝和鲍勃通过一个对称加密算法生成一个对话密钥，加密接下来的通信内容。 结文中阐述不妥之处还望雅正，不吝感激。 部分摘自Damonare 感谢。 以上。","categories":[],"tags":[{"name":"https","slug":"https","permalink":"http://54skyray.cn/tags/https/"},{"name":"ssl","slug":"ssl","permalink":"http://54skyray.cn/tags/ssl/"}]},{"title":"git的回滚操作","slug":"git的回滚操作","date":"2016-05-14T17:23:47.000Z","updated":"2019-04-12T08:19:25.677Z","comments":true,"path":"2016/05/15/git的回滚操作/","link":"","permalink":"http://54skyray.cn/2016/05/15/git的回滚操作/","excerpt":"前言一直在使用git作为版本管理器,但是有一次线上出问题,但是又有未通过完整测试的代码在mater分支上,那么所需要的操作就是 回滚代码到上一个已通过测试的master版本 -&gt; 修复bug -&gt; 发布 -&gt; 还原master -&gt; 合并修改了bug的分支 -&gt; 重新上预发布,请展开全文开始演练.","text":"前言一直在使用git作为版本管理器,但是有一次线上出问题,但是又有未通过完整测试的代码在mater分支上,那么所需要的操作就是 回滚代码到上一个已通过测试的master版本 -&gt; 修复bug -&gt; 发布 -&gt; 还原master -&gt; 合并修改了bug的分支 -&gt; 重新上预发布,请展开全文开始演练. 正文做准备为了简单描述,我们把定义几个分支.init-master //最初的masteruntest-master //未完全通过测试的master,其是远程仓库上最新的masterbugfix/fix_some_bug //修改的bug分支 操作 拉取untest-master 首先是切换并更新master,注意此时的master是untest-master,也就是我们要对其进行回滚操作 12git checkout mastergit pull origin master 回滚到init-master 回滚操作首先需要定义到要回滚到的提交记录,然后强制回滚到该记录上,注意这里的操作只是对本地分支的操作并不会影响到远程分支 123//使用git log查看其提交记录,确定要回滚到的`commit id`git log g reset --hard [commit id] 回滚远程master 回滚操作是把你当前的分支强制提交到master上也就是加-f参数指明强制覆盖,该命令需要你有相应的master权限.这样的话master上就是之前的版本了.那么接下来就是一般的修改bug了. 1git push -u origin master -f 修复bug,并发布 bug的修复是在当前init-master分支的基础上,切出一个新的分支,然后像平常一样修改提交,最后合到init-master上. 123git checkout -b bugfix/fix_some_bug// 修复bug// 发布 取消回滚 取消回滚则是重新强制恢复到修改过的版本,然后就可以强制回滚到任意版本了 12git reflog 查看该分支的变动,可以确定其commit idgit reset --hard [commit id] 合并修改了bug的分支 - 这次回滚后你处在untest-master分支上,该分支上是没有bugfix/fix_some_bug修复bug的代码的,那么把他合并过来.然后推送上去,那么master就是当前最新的版本了 12git merge bugfix/fix_some_buggit push origin master 总结以上是操作是必须需要有master权限的,否则无法回滚,另外如果担心代码丢失那么在untest-master分支上再次checkout一个分支,这样即使master再怎么变,这个分支仍然是untest-master的副本.最后git是一款强大的版本工具,其可能有更加简单的方法,欢迎分享. 结文中阐述不妥之处还望雅正，不吝感激。 转载请注明:天雷 以上。","categories":[],"tags":[{"name":"git","slug":"git","permalink":"http://54skyray.cn/tags/git/"}]},{"title":"Java使用HTTPClient模拟Http请求","slug":"Java使用HTTPClient模拟Http请求","date":"2016-03-19T01:36:58.000Z","updated":"2020-11-25T03:04:23.693Z","comments":true,"path":"2016/03/19/Java使用HTTPClient模拟Http请求/","link":"","permalink":"http://54skyray.cn/2016/03/19/Java使用HTTPClient模拟Http请求/","excerpt":"前言有一个需求需要对接第三方系统，而我选择使用HTTPClient来拉数据，却走了不少弯路，所以写出来让需要用到的人看到.","text":"前言有一个需求需要对接第三方系统，而我选择使用HTTPClient来拉数据，却走了不少弯路，所以写出来让需要用到的人看到. 正文简要介绍使用规则 这里的Apache HttpClient模块是HttpClient 4.0（org.apache.http.*） HttpClient常用HttpGet和HttpPost这两个类，分别对应Get方式和Post方式。 创建HttpGet或HttpPost对象，将要请求的URL通过构造方法传入HttpGet或HttpPost对象。 使用DefaultHttpClient类的execute方法发送HTTP GET或HTTP POST请求，并返回HttpResponse对象。 通过HttpResponse接口的getEntity方法返回响应信息，并进行相应的处理。 如果使用HttpPost方法提交HTTP POST请求，则需要使用HttpPost类的setEntity方法设置请求参数。参数则必须用NameValuePair[]数组存储。 HttpGet模拟实操123456789101112131415161718192021222324252627282930313233 public String doGet() &#123; String uriAPI = &quot;http://XXXXX?str=I+am+get+String&quot;; String result= &quot;&quot;; // HttpGet httpRequst = new HttpGet(URI uri); // HttpGet httpRequst = new HttpGet(String uri); // 创建HttpGet或HttpPost对象，将要请求的URL通过构造方法传入HttpGet或HttpPost对象。 HttpGet httpRequst = new HttpGet(uriAPI); // new DefaultHttpClient().execute(HttpUriRequst requst); try &#123; //使用DefaultHttpClient类的execute方法发送HTTP GET请求，并返回HttpResponse对象。 HttpResponse httpResponse = new DefaultHttpClient().execute(httpRequst);//其中HttpGet是HttpUriRequst的子类 if(httpResponse.getStatusLine().getStatusCode() == 200) &#123; HttpEntity httpEntity = httpResponse.getEntity(); result = EntityUtils.toString(httpEntity);//取出应答字符串 // 一般来说都要删除多余的字符 result.replaceAll(&quot;\\r&quot;, &quot;&quot;);//去掉返回结果中的&quot;\\r&quot;字符，否则会在结果字符串后面显示一个小方格 &#125; else httpRequst.abort(); &#125; catch (ClientProtocolException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); result = e.getMessage().toString(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); result = e.getMessage().toString(); &#125; return result; &#125; HttpPost模拟实操12345678910111213141516171819202122232425262728293031323334public String doPost() &#123; String uriAPI = &quot;http://XXXXXX&quot;;//Post方式没有参数在这里 String result = &quot;&quot;; HttpPost httpRequst = new HttpPost(uriAPI);//创建HttpPost对象 List &lt;NameValuePair&gt; params = new ArrayList&lt;NameValuePair&gt;(); params.add(new BasicNameValuePair(&quot;str&quot;, &quot;I am Post String&quot;)); try &#123; httpRequst.setEntity(new UrlEncodedFormEntity(params,HTTP.UTF_8)); HttpResponse httpResponse = new DefaultHttpClient().execute(httpRequst); if(httpResponse.getStatusLine().getStatusCode() == 200) &#123; HttpEntity httpEntity = httpResponse.getEntity(); result = EntityUtils.toString(httpEntity);//取出应答字符串 &#125; &#125; catch (UnsupportedEncodingException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); result = e.getMessage().toString(); &#125; catch (ClientProtocolException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); result = e.getMessage().toString(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); result = e.getMessage().toString(); &#125; return result; &#125; 加料12345678910HttpParams httpParameters = new BasicHttpParams(); HttpConnectionParams.setConnectionTimeout(httpParameters, 10*1000);//设置请求超时10秒 HttpConnectionParams.setSoTimeout(httpParameters, 10*1000); //设置等待数据超时10秒 HttpConnectionParams.setSocketBufferSize(params, 8192); HttpClient httpclient = new DefaultHttpClient(httpParameters); //此时构造DefaultHttpClient时将参数传入 由于是联网，在AndroidManifest.xml中添加网络连接的权限 &lt;uses-permission android:name=&quot;android.permission.INTERNET&quot;/&gt; 结转载请注明出处:天雷 以上","categories":[],"tags":[{"name":"HTTPClient","slug":"HTTPClient","permalink":"http://54skyray.cn/tags/HTTPClient/"},{"name":"Http请求","slug":"Http请求","permalink":"http://54skyray.cn/tags/Http请求/"}]},{"title":"Internet协议入门","slug":"Internet协议入门","date":"2016-03-02T11:07:09.000Z","updated":"2019-04-12T08:15:40.050Z","comments":true,"path":"2016/03/02/Internet协议入门/","link":"","permalink":"http://54skyray.cn/2016/03/02/Internet协议入门/","excerpt":"前言此篇博客则用来作为一个大纲式的内容，按照层级划分，逐步介绍各层级的协议以及他们所起的作用。若有错误之处，欢迎批评指正。 劳于读书，逸于作文。","text":"前言此篇博客则用来作为一个大纲式的内容，按照层级划分，逐步介绍各层级的协议以及他们所起的作用。若有错误之处，欢迎批评指正。 劳于读书，逸于作文。 正文概述互联网的实现，分成好几层。每一层都有自己的功能，就像建筑物一样，每一层都靠下一层支持。 模型划分首先我们需要明白的事互联网的实现是分层级的，那么这个层级的划分根据不同的模型又有一些不同。其中又有两个模型的划分是我们最常见到的，一个是OSI七层划分，另一个是TCP/IP五层划分。他们分别把互联网分成了七层和五层。 OSI和TCP/IP模型是很基础但又非常重要的网络基础知识 OSI七层模型 OSI的层 功能 TCP/IP协议族 应用层 文件传输，电子邮件，文件服务，虚拟终端 TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 表示层 数据格式化，代码转换，数据加密 没有协议 会话层 解除或建立与别的接点的联系 没有协议 传输层 提供端对端的接口 TCP，UDP 网络层 为数据包选择路由 IP，ICMP，RIP，OSPF，BGP，IGMP 数据链路层 传输有地址的帧以及错误检测功能 SLIP，CSLIP，PPP，ARP，RARP，MTU 物理层 以二进制数据形式在物理媒体上传输数据 ISO2110，IEEE802，IEEE802.2 层与协议每一层都是为了完成一种功能。为了实现这些功能，就需要大家都遵守共同的规则。 大家都遵守的规则，就叫做”协议”（protocol）。 这个协议就是我们所说的互联网协议（internet protocol）,每一层都有若干个协议，他们共同构成了我们所要讲的互联网协议。 由以上表格我们可以看出，在OSI七层协议模型里会话层和表示层是没有协议的，这里我们取的是TCP/IP模型，分成五层也比较容易解释。 那么这五层又都是什么呢？从上到下分别是： 层级 网络设备 应用层 也就是用户使用的应用了。 传输层 四层交换机、也有工作在四层的路由器 网络层 路由器、三层交换机 数据链路层 网桥（现已很少使用）、以太网交换机（二层交换机）、网卡（其实网卡是一半工作在物理层、一半工作在数据链路层） 物理层 网卡，光纤，CAT-5线，中继器、集线器、还有我们通常说的双绞线也工作在物理层 如上表格所示，最底下的一层叫做物理层（Physical Layer），最上面的一层叫做应用层（Application Layer），中间的三层（自下而上）分别是数据链路层（Data Link Layer）、网络层（Network Layer）和传输层（Transport Layer）。越下面的层，越靠近硬件；越上面的层，越靠近用户。下面来介绍每一层的功能，着重介绍每一层的主要协议 物理层 物理层规定:为传输数据所需要的物理链路创建、维持、拆除，而提供具有机械的，电子的，功能的和规范的特性 上面百度百科对于物理层的解释说白了就是要把电脑连在一块，方法呢，可以用光缆、电缆、双绞线、无线电波等方式。物理层就是把电脑连接起来的物理手段。它主要规定了网络的一些电气特性，作用是负责传送0和1的电信号。 数据链路层 在两个网络实体之间提供数据链路连接的创建、维持和释放管理。构成数据链路数据单元（frame：数据帧或帧），并对帧定界、同步、收发顺序的控制。 定义上面说的网络实体也就是我们日常用到的手机电脑等联网设备了，我们刚刚了解到不同网络实体之间通过一些物理手段（光缆，双绞线，无线电波等）连接在了一起，来进行传输0和1电信号。单纯的传输0和1没有任何意义，肯定是要规定电信号的解读方式，多少个电信号是一组？每一组代表的意义又是什么？ 这就是数据链路层的功能，规定这些电信号的分组方式。 以太网协议刚刚开始的时候，每一家公司都有自己的一套对于电信号的解读方式，后来随着时间的推移，一种叫做以太网(Ethernet)的协议，占据了主导地位。 以太网规定，一组电信号构成一个数据包，叫做”帧”（Frame）。每一帧分成两个部分：标头（Head）和数据（Data）。 标头包含数据包的一些说明项，比如发送者、接受者、数据类型等等；数据则是数据包的具体内容。 标头的长度，固定为18字节。数据的长度，最短为46字节，最长为1500字节。因此，整个帧最短为64字节，最长为1518字节。如果数据很长，就必须分割成多个帧进行发送。 MAC地址我想在日常上网过程中，最为熟悉的就是用一根网线连接端口和电脑了吧，网线连接电脑实际上是连接的这个玩意儿： 上面就是我们所说的网卡了，它在物理层和数据链路层两个层级工作，正所谓能力越大责任越大，网卡的重要性自然不言而喻了。前面说，以太网规定每一个数据包都有一个标头（Head）来说明发送者，接受者信息，数据类型等信息。而网卡就是以太网规定的来标明发送者和接受者信息的工具。 网卡的地址，就是数据包的发送地址和接收地址，这叫做MAC地址。 这个Mac地址自然就是发送者，接受者信息的了，通过这个每台电脑独一无二的地址计算机就能通过一些方式找到另一台电脑了。每块网卡出厂的时候，都有一个全世界独一无二的MAC地址，长度是48个二进制位，通常用12个十六进制数表示。有了MAC地址，就可以定位网卡和数据包的路径了。 广播我们现在有了网卡，也知道每一块网卡都有一个世界上独一无二的Mac地址，那发送者应该怎么去找接受者这台设备呢，换句话说发送者怎么才能知道接受者的Mac地址呢？这就需要另一个协议了叫做ARP协议，这个协议留在后面介绍。这里我们只需要知道，发送者必须要知道接受者的Mac地址才能准确的发送数据。 以太网采用了一种广撒网的方式，发送者发送的数据包会发送给本网络内所有的计算机，然后由接收到数据包的计算机来判断自己是不是接收方。 如图所示，红色主机是发送方，绿色某一台是接收方，数据包会发送给同一个子网络的所有绿色主机，然后由绿色主机根据数据包的标头来判断自己是不是接收方。如果是，就接受这个包，不是则丢弃。这种发送数据的方式就是广播。 综上，有了对于数据包的定义，网卡的Mac地址，广播的发送方式，数据链路层基本就算完整了，然后不同计算机之间就可以传送数据了。 网络层 网络层使两终端系统能够互连且决定最佳路径，并具有一定的拥塞控制和流量控制的能力。 ——网络层 网络层的产生走到这里我们实现的只是在一个子网络里传送数据。但我们知道，互联网实际上是由大大小小的子网络组成的： 大到一个ISP（因特网服务提供商，国内较大的比如移动电信等），小到一个公司的局域网，正事这些大大小小的子网络组成了庞大的互联网体系。但实际上，广播的方式只能在子网络内进行，不同子网络之间广播方式是行不通的。 因此我们需要一种方法能够判断两台主机是否在同一个子网络之内，如果在同一个子网络就以广播的方式传输数据，如果不在同一个子网络就以路由的方式传输（路由是个比较大的概念，本文不涉及），关于路由协议的了解戳这里，MAC地址做不到这一点，它只和厂商有关，和计算机所处的网络并没有关系。 这就导致了”网络层”的诞生。它的作用是引进一套新的地址，使得我们能够区分不同的计算机是否属于同一个子网络。这套地址就叫做”网络地址”，简称”网址”。 网址的出现，使得每台计算机都有了两个地址，一个是出生就带着不会改变的Mac地址，一个是后期网络管理员分配的可变的网络地址。网址判断两台计算机是否在同一个子网络，Mac地址则是将数据准确的传递到目标计算机中。因此逻辑上可以判断必定是先处理网络地址，再处理Mac地址。 IP协议规定网络地址的协议，叫做IP协议。它所定义的地址，就被称为IP地址。 现在广泛采用的是IP协议第四版，简称IPv4。这个版本规定，网络地址由32个二进制位组成，IPV6则是64个二进制组成。 由于IPV6还没有广泛应用，这里还是用IPV4讲解。一般我们用分成四段（IPV6分成八段）的十进制数表示IP地址，从0.0.0.0一直到255.255.255.255。这个地址分成两部分，前一部分是网络部分，后一部分代表主机。But!!!网络部分具体是前16位还是前24位，我们没法从IP地址进行判断，这是我们就需要另一参数叫做子网掩码。 所谓”子网掩码”，就是表示子网络特征的一个参数。它在形式上等同于IP地址，也是一个32位二进制数字，它的网络部分全部为1，主机部分全部为0。比如，IP地址172.16.254.1，如果已知网络部分是前24位，主机部分是后8位，那么子网络掩码就是11111111.11111111.11111111.00000000，写成十进制就是255.255.255.0。 知道”子网掩码”，我们就能判断，任意两个IP地址是否处在同一个子网络。方法是将两个IP地址与子网掩码分别进行AND运算（两个数位都为1，运算结果为1，否则为0），然后比较结果是否相同，如果是的话，就表明它们在同一个子网络中，否则就不是。 比如，已知IP地址172.16.254.1和172.16.254.233的子网掩码都是255.255.255.0，请问它们是否在同一个子网络？两者与子网掩码分别进行AND运算，结果都是172.16.254.0，因此它们在同一个子网络。 那么问题来了，IP地址放在哪里存储呢？是的，我们可以直接存储在前面提到的以太网数据包的Data部分。 IP地址长这样： “标头”部分主要包括版本、长度、IP地址等信息，”数据”部分则是IP数据包的具体内容。现在把它加到以太网数据包里面： IP数据包的”标头”部分的长度为20到60字节，整个数据包的总长度最大为65,535字节。因此，理论上，一个IP数据包的”数据”部分，最长为65,515字节。前面说过，以太网数据包的”数据”部分，最长只有1500字节。因此，如果IP数据包超过了1500字节，它就需要分割成几个以太网数据包，分开发送了。 ARP协议现在为止我们必须知道两个地址，一个是IP地址，一个是Mac地址才能把数据发送到目标主机，那么IP地址是已知的（后文解释），MAC地址怎么获取呢？ 我们需要一种能通过IP地址得知MAC地址的机制，这个极致就是ARP协议。 那么，这里又分成两种情况，一种是两台计算机在同一个子网络，那么我们可以用ARP协议，得到对方的MAC地址。ARP协议也是发出一个数据包（包含在以太网数据包中），其中包含它所要查询主机的IP地址，在对方的MAC地址这一栏，填的是FF:FF:FF:FF:FF:FF，表示这是一个”广播”地址。它所在子网络的每一台主机，都会收到这个数据包，从中取出IP地址，与自身的IP地址进行比较。如果两者相同，都做出回复，向对方报告自己的MAC地址，否则就丢弃这个包。 另一种情况是两台计算机不在同一个子网络，那么事实上没有办法得到对方的MAC地址，只能把数据包传送到两个子网络连接处的”网关”（gateway），让网关（后文解释）去处理。 总结这一层为止，如果目标主机和本机在同一个子网络，我们通过IP地址，子网掩码比较得出在同一个子网络的结果，在通过ARP协议得到目标主机的Mac地址，发送！Success！ 如果目标主机和本机不在同一个子网络，我们通过IP地址，子网掩码比较得出在同一个子网络的结果，然后交给本网络的网关A处理，网关A根据路由协议得到目标主机所在子网络的网关B，网关B再通过IP地址判断得出和目标主机在同一个子网络，然后再通过ARP协议获取Mac地址，发送！Success! 传输层 该层的协议为应用进程提供端到端的通信服务。它提供面向连接的数据流支持、可靠性、流量控制、多路复用等服务。 传输层的产生我们现在成功的实现了主机和主机之间的通信，那么问题又来了，主机之间不同的程序该怎么区分这个数据是不是发送给自己的呢。要知道，当你正在QQ聊天的时候，微信发送过来的消息内容呈现在了QQ界面，这会让计算机懵逼的！太混乱了！ 这个时候我们就需要一个新的参数了！这个参数就是端口。 可连接两个或两个以上不同之电路装置使之能够传递电子或任何形式讯号之装置. 它其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。 不同的程序在计算机中所占用的端口是不同的，确切的说是不能相同的，否则就混乱了。比如，HTTP所占用的端口一般是80，HTTPS所占用的端口一般是443。 端口是0到65535之间的一个整数，正好16个二进制位。0到1023的端口被系统占用，用户只能选用大于1023的端口。不管是浏览网页还是在线聊天，应用程序会随机选用一个端口，然后与服务器的相应端口联系。 确切的说，传输层实现的是端对端的服务，网络层实现的仅仅是主机到主机之间的服务。只要确定主机和端口，我们就能实现程序之间的交流。因此，Unix系统就把主机+端口，叫做”套接字”（socket）。 UDP协议现在又出了一个新的数据，就是端口信息。现在以太网数据包里已经包括发送者，接受者信息，数据类型，IP地址数据包，UDp数据包。 UDP数据包同样是由标头和数据组成： 标头部分主要定义了发出端口和接收端口，数据部分定义了具体的内容。然后把它放在IP地址数据包的数据部分，前面我们说过IP数据包是放在以太网数据包的数据里面的，那么现在整个以太网数据包就成了这样： UDP数据包非常简单，”标头”部分一共只有8个字节，总长度不超过65,535字节，一个IP数据包正好可以容纳。 TCP协议为了解决这个问题，提高网络可靠性，TCP协议就诞生了。这个协议非常复杂，但可以近似认为，它就是有确认机制的UDP协议，每发出一个数据包都要求确认。如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。 因此，TCP协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。TCP数据包和UDP数据包一样，都是内嵌在IP数据包的”数据”部分。TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。 应用层 应用层直接和应用程序接口并提供常见的网络应用服务。 应用层介绍应用程序收到”传输层”的数据，接下来就要进行解读。由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。 “应用层”的作用，就是规定应用程序的数据格式。 举例来说，TCP协议可以为各种各样的程序传递数据，比如Email、WWW、FTP等等。那么，必须有不同协议规定电子邮件、网页、FTP数据的格式，这些应用程序协议就构成了”应用层”。 这是最高的一层，直接面对用户。它的数据就放在TCP数据包的”数据”部分。因此，现在的以太网的数据包就变成下面这样： 上面买的坑改填了，我们前面说过，我们对于目标主机的IP地址肯定知道的，为什么呢？还有就是当两台计算机不在同一个子网络的时候，我们需要通过本机所在子网络的网关A，再通过路由协议得到目标主机子网络的网关B，由网关B将我们要发送给目标主机的数据包发送给目标主机。那么，网关又是什么呢？ DNS协议我们都知道由于IP地址不方便记忆，我们创造了域名这个概念。 DNS（网域名称系统，Domain Name System，有时也简称为域名）是因特网的一项核心服务，它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP地址数串。 例如，damonare.cn是一个域名，和IP地址119.29.180.47相对应。DNS就像是一个自动的电话号码簿，我们可以直接拨打damonare的名字来代替电话号码（IP地址）。我们直接调用网站的名字以后，DNS就会将便于人类使用的名字（如 damonare.cn）转化成便于机器识别的IP地址（如119.29.180.47）。 已知DNS服务器为8.8.8.8（这个和IP地址一样管理员告知或是通过自行设置的），于是我们向这个地址发送一个DNS数据包（53端口）： DNS服务器做出响应，告诉我们Google的IP地址是172.194.72.105。于是，我们知道了对方的IP地址。 网关 网关要区别于路由器（由于历史的原因，许多有关TCP/IP的文献曾经把网络层使用的路由器（英语：Router）称为网关，在今天很多局域网采用都是路由来接入网络，因此现在通常指的网关就是路由器的IP），经常在家庭中或者小型企业网络中使用，用于连接局域网和Internet。 前面我们已经说过发送以太网数据包，需要知道两个地址： 对方的MAC地址 对方的IP地址 有了这两个地址，数据包才能准确送到接收者手中。但是，前面说过，MAC地址有局限性，如果两台电脑不在同一个子网络，就无法知道对方的MAC地址，必须通过网关（gateway）转发。 上图中，1号电脑要向4号电脑发送一个数据包。它先判断4号电脑是否在同一个子网络，结果发现不是（后文介绍判断方法），于是就把这个数据包发到网关A。网关A通过路由协议，发现4号电脑位于子网络B，又把数据包发给网关B，网关B再转发到4号电脑。 DHCP协议新买的电脑通常你必须做一些设置，才能上网，有时，管理员（或者ISP）会告诉你下面四个参数，你把它们填入操作系统，计算机就能连上网了： 本机的IP地址 子网掩码 网关的IP地址 DNS的IP地址 由于它们是给定的，计算机每次开机，都会分到同样的IP地址，所以这种情况被称作”静态IP地址上网”。如下图Window静态IP上网设置界面： 这样的设置很专业，但普通用户望而生畏，而且如果一台电脑的IP地址保持不变，其他电脑就不能使用这个地址，不够灵活。出于这两个原因，大多数用户使用”动态IP地址上网”。 动态IP地址上网使用的协议就是DHCP协议，这个协议规定，每一个子网络中，有一台计算机负责管理本网络的所有IP地址，它叫做”DHCP服务器”。新的计算机加入网络，必须向”DHCP服务器”发送一个”DHCP请求”数据包，申请IP地址和相关的网络参数。 前面说过，如果两台计算机在同一个子网络，必须知道对方的MAC地址和IP地址，才能发送数据包。但是，新加入的计算机不知道这两个地址，怎么发送数据包呢？ DHCP协议做了一些巧妙的规定。 首先DHCP协议是建立在UDP协议之上，所以整个数据包是这样的： (1).最前面的”以太网标头”，设置发出方（本机）的MAC地址和接收方（DHCP服务器）的MAC地址。前者就是本机网卡的MAC地址，后者这时不知道，就填入一个广播地址：FF-FF-FF-FF-FF-FF。 (2).后面的”IP标头”，设置发出方的IP地址和接收方的IP地址。这时，对于这两者，本机都不知道。于是，发出方的IP地址就设为0.0.0.0，接收方的IP地址设为255.255.255.255。 (3).最后的”UDP标头”，设置发出方的端口和接收方的端口。这一部分是DHCP协议规定好的，发出方是68端口，接收方是67端口。 这个数据包构造完成后，就可以发出了。以太网是广播发送，同一个子网络的每台计算机都收到了这个包。因为接收方的MAC地址是FF-FF-FF-FF-FF-FF，看不出是发给谁的，所以每台收到这个包的计算机，还必须分析这个包的IP地址，才能确定是不是发给自己的。当看到发出方IP地址是0.0.0.0，接收方是255.255.255.255，于是DHCP服务器知道”这个包是发给我的”，而其他计算机就可以丢弃这个包。 接下来，DHCP服务器读出这个包的数据内容，分配好IP地址，发送回去一个”DHCP响应”数据包。这个响应包的结构也是类似的，以太网标头的MAC地址是双方的网卡地址，IP标头的IP地址是DHCP服务器的IP地址（发出方）和255.255.255.255（接收方），UDP标头的端口是67（发出方）和68（接收方），分配给请求端的IP地址和本网络的具体参数则包含在Data部分。 新加入的计算机收到这个响应包，于是就知道了自己的IP地址、子网掩码、网关地址、DNS服务器等等参数。 结应用层比较重要的协议还有大名鼎鼎的HTTP协议，后续会更新 文中阐述不妥之处还望雅正，不吝感激。 转载请注明出处:天雷 以上。 参考文章: 互联网协议入门（一）","categories":[],"tags":[{"name":"http","slug":"http","permalink":"http://54skyray.cn/tags/http/"},{"name":"网络协议","slug":"网络协议","permalink":"http://54skyray.cn/tags/网络协议/"}]},{"title":"HashMap原理解析-面试常用划重点","slug":"HashMap原理解析-面试常用划重点","date":"2016-01-02T07:25:52.000Z","updated":"2019-04-12T08:19:11.344Z","comments":true,"path":"2016/01/02/HashMap原理解析-面试常用划重点/","link":"","permalink":"http://54skyray.cn/2016/01/02/HashMap原理解析-面试常用划重点/","excerpt":"前言数据结构几乎是面试的日常了，其中HashMap更是常客,很多人说到HashMap都能”画虎烂”两句,但是类似： 高并发中HashMap为何会出现死锁？ Java8中，HashMap的结构有如何优化？ 却有很多人吃了哑巴亏，这篇博文就在这个两个问题上展开，看看它背后的故事~!","text":"前言数据结构几乎是面试的日常了，其中HashMap更是常客,很多人说到HashMap都能”画虎烂”两句,但是类似： 高并发中HashMap为何会出现死锁？ Java8中，HashMap的结构有如何优化？ 却有很多人吃了哑巴亏，这篇博文就在这个两个问题上展开，看看它背后的故事~! HashMap简介众所周知，HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫做Entry。这些个键值对（Entry）分散存储在一个数组当中，这个数组就是HashMap的主干。 HashMap基本结构与原理 HashMap数组每一个元素的初始值都是Null。 对于HashMap，我们最常使用的是两个方法：Get 和 Put。1.Put方法的原理调用Put方法的时候发生了什么呢？ 比如调用 hashMap.put(&quot;apple&quot;, 0) ，插入一个Key为“apple“的元素。这时候我们需要利用一个哈希函数来确定Entry的插入位置（index）： index = Hash（“apple”） 假定最后计算出的index是2，那么结果如下：但是，因为HashMap的长度是有限的，当插入的Entry越来越多时，再完美的Hash函数也难免会出现index冲突的情况。比如下面这样：这时候该怎么办呢？我们可以利用链表来解决。HashMap数组的每一个元素不止是一个Entry对象，也是一个链表的头节点。每一个Entry对象通过Next指针指向它的下一个Entry节点。当新来的Entry映射到冲突的数组位置时，只需要插入到对应的链表即可：需要注意的是，新来的Entry节点插入链表时，使用的是“头插法”。至于为什么不插入链表尾部，后面会有解释。 2.Get方法的原理使用Get方法根据Key来查找Value的时候，发生了什么呢？ 首先会把输入的Key做一次Hash映射，得到对应的index： index = Hash（“apple”） 由于刚才所说的Hash冲突，同一个位置有可能匹配到多个Entry，这时候就需要顺着对应链表的头节点，一个一个向下来查找。假设我们要查找的Key是“apple”： 第一步，我们查看的是头节点Entry6，Entry6的Key是banana，显然不是我们要找的结果。 第二步，我们查看的是Next节点Entry1，Entry1的Key是apple，正是我们要找的结果。 之所以把Entry6放在头节点，是因为HashMap的发明者认为，后插入的Entry被查找的可能性更大。 深入HashMap,解析前言中的问题首先明确一点，HashMap的默认长度是16，并且每次自动扩展或是手动初始化时，长度必须是2的幂.之所以选择16，是为了服务与Key映射到index的Hash算法 之前说过，从Key映射到HashMap数组的对应位置，会用到一个Hash函数： index = Hash（“apple”） 如何实现一个尽量均匀分布的Hash函数呢？我们通过利用Key的HashCode值来做某种运算。 以前的计算方式: index = HashCode（Key） % Length现在的计算方式: index = HashCode（Key） &amp; （Length - 1） 以前的取模运算的方式固然简单，但是效率很低。为了实现高效的Hash算法，HashMap的发明者采用了位运算的方式。下面我们以值为“book”的Key来演示整个过程： 1.计算book的hashcode，结果为十进制的3029737，二进制的101110001110101110 1001。 2.假定HashMap长度是默认的16，计算Length-1的结果为十进制的15，二进制的1111。 3.把以上两个结果做与运算，101110001110101110 1001 &amp; 1111 = 1001，十进制是9，所以 index=9。 可以说，Hash算法最终得到的index结果，完全取决于Key的Hashcode值的最后几位。 这样做不但效果上等同于取模而且还大大提高了性能。至于为什么采用16，我们可以试试长度是10会出现什么问题. 假设HashMap的长度是10，重复刚才的运算步骤：单独看这个结果，表面上并没有问题。我们再来尝试一个新的HashCode 101110001110101110 1011 ：让我们再换一个HashCode 101110001110101110 1111 试试：是的，虽然HashCode的倒数第二第三位从0变成了1，但是运算的结果都是1001。也就是说，当HashMap长度为10的时候，有些index结果的出现几率会更大，而有些index结果永远不会出现（比如0111）！ 这样，显然不符合Hash算法均匀分布的原则。 反观长度16或者其他2的幂，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。 来说说死锁产生的原因!通过上文咱们知道HashMap初始容量大小为16,一般来说，Hash表这个容器当有数据要插入时，都会检查容量有没有超过设定的thredhold，如果超过，需要增大Hash表的尺寸，但是这样一来，整个Hash表里的元素都需要被重算一遍。这叫rehash，这个成本相当的大。 HashMap是非线程安全，死锁一般都是产生于并发情况下。我们假设有二个进程T1、T2，HashMap容量为2,T1线程放入key A、B、C、D、E。在T1线程中A、B、C Hash值相同，于是形成一个链接，假设为A-&gt;C-&gt;B，而D、E Hash值不同，于是容量不足，需要新建一个更大尺寸的Hash表，然后把数据从老的Hash表中迁移到新的Hash表中(refresh)。这时T2进程闯进来了，T1暂时挂起，T2进程也准备放入新的key，这时也发现容量不足，也refresh一把。refresh之后原来的链表结构假设为C-&gt;A，之后T1进程继续执行，链接结构为A-&gt;C,这时就形成A.next=B,B.next=A的环形链表。一旦取值进入这个环形链表就会陷入死循环。 那有什么替代的方案呢？使用ConcurrentHashMap进行替代，ConcurrentHashMap是一个线程安全的HashTable。可能有人会使用HashTable。当然HashTable也是线程安全,但HashTable锁定的是整个Hash表，效率相对比较低。而ConcurrentHashMap可以做到读取数据不加锁，并且其内部的结构可以让其在进行写操作的时候能够将锁的粒度保持地尽量地小。 结文中阐述不妥之处还望雅正，不吝感激。 转载请注明出处:天雷 以上","categories":[],"tags":[{"name":"hash","slug":"hash","permalink":"http://54skyray.cn/tags/hash/"},{"name":"HashMap","slug":"HashMap","permalink":"http://54skyray.cn/tags/HashMap/"},{"name":"数组","slug":"数组","permalink":"http://54skyray.cn/tags/数组/"},{"name":"链表","slug":"链表","permalink":"http://54skyray.cn/tags/链表/"},{"name":"数据结构","slug":"数据结构","permalink":"http://54skyray.cn/tags/数据结构/"}]},{"title":"深度分析 Java ClassLoader 工作机制","slug":"详细深入分析JavaClassLoader工作机制","date":"2015-12-23T02:32:18.000Z","updated":"2019-04-12T08:18:25.606Z","comments":true,"path":"2015/12/23/详细深入分析JavaClassLoader工作机制/","link":"","permalink":"http://54skyray.cn/2015/12/23/详细深入分析JavaClassLoader工作机制/","excerpt":"前言大家都知道，当我们写好一个 Java 程序之后，不是管是 C/S 还是 B/S 应用，都是由若干个 .class 文件组织而成的一个完整的 Java 应用程序，当程序在运行时，即会调用该程序的一个入口函数来调用系统的相关功能，而这些功能都被封装在不同的 class 文件当中，所以经常要从这个 class 文件中要调用另外一个 class 文件中的方法，如果另外一个文件不存在的，则会引发系统异常。而程序在启动的时候，并不会一次性加载程序所要用的所有class文件，而是根据程序的需要，通过Java的类加载机制（ClassLoader）来动态加载某个 class 文件到内存当中的，从而只有 class 文件被载入到了内存之后，才能被其它 class 所引用。所以 ClassLoader 就是用来动态加载 class 文件到内存当中用的。","text":"前言大家都知道，当我们写好一个 Java 程序之后，不是管是 C/S 还是 B/S 应用，都是由若干个 .class 文件组织而成的一个完整的 Java 应用程序，当程序在运行时，即会调用该程序的一个入口函数来调用系统的相关功能，而这些功能都被封装在不同的 class 文件当中，所以经常要从这个 class 文件中要调用另外一个 class 文件中的方法，如果另外一个文件不存在的，则会引发系统异常。而程序在启动的时候，并不会一次性加载程序所要用的所有class文件，而是根据程序的需要，通过Java的类加载机制（ClassLoader）来动态加载某个 class 文件到内存当中的，从而只有 class 文件被载入到了内存之后，才能被其它 class 所引用。所以 ClassLoader 就是用来动态加载 class 文件到内存当中用的。 正文ClassLoader 作用： 负责将 Class 加载到 JVM 中 审查每个类由谁加载（父优先的等级加载机制） 将 Class 字节码重新解析成 JVM 统一要求的对象格式 ClassLoader 类结构分析为了更好的理解类的加载机制，我们来深入研究一下ClassLoader和他的方法。 public abstract class ClassLoader ClassLoader类是一个抽象类，sun公司是这么解释这个类的：1234567/** * A class loader is an object that is responsible for loading classes. The * class ClassLoader is an abstract class. Given the binary name of a class, a class loader should attempt to * locate or generate data that constitutes a definition for the class. A * typical strategy is to transform the name into a file name and then read a * &quot;class file&quot; of that name from a file system.**/ 以下是 ClassLoader 常用到的几个方法及其重载方法： ClassLoader defineClass(byte[], int, int) 把字节数组 b中的内容转换成 Java 类，返回的结果是java.lang.Class类的实例。这个方法被声明为final的 findClass(String name) 查找名称为 name的类，返回的结果是java.lang.Class类的实例 loadClass(String name) 加载名称为 name的类，返回的结果是java.lang.Class类的实例 resolveClass(Class&lt;?&gt;) 链接指定的 Java 类 其中 defineClass 方法用来将 byte 字节流解析成 JVM 能够识别的 Class 对象，有了这个方法意味着我们不仅仅可以通过 class 文件实例化对象，还可以通过其他方式实例化对象，如果我们通过网络接收到一个类的字节码，拿到这个字节码流直接创建类的 Class 对象形式实例化对象。如果直接调用这个方法生成类的 Class 对象，这个类的 Class 对象还没有 resolve ，这个 resolve 将会在这个对象真正实例化时才进行。 接下来我们看loadClass方法的实现方式： 12345678910111213141516171819202122232425262728293031323334protected Class&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 该方法大概意思： 使用指定的二进制名称来加载类，这个方法的默认实现按照以下顺序查找类： 调用findLoadedClass(String) 方法检查这个类是否被加载过 使用父加载器调用 loadClass(String) 方法，如果父加载器为 Null，类加载器装载虚拟机内置的加载器调用 findClass(String)方法装载类， 如果，按照以上的步骤成功的找到对应的类，并且该方法接收的 resolve 参数的值为 true,那么就调用resolveClass(Class) 方法来处理类。 ClassLoader 的子类最好覆盖 findClass(String) 而不是这个方法。 除非被重写，这个方法默认在整个装载过程中都是同步的（线程安全的）。 ClassLoader 的等级加载机制Java默认提供的三个ClassLoader BootStrap ClassLoader：称为启动类加载器，是Java类加载层次中最顶层的类加载器，负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar等，可通过如下程序获得该类加载器从哪些地方加载了相关的jar或class文件： 12345678910public class BootStrapTest&#123; public static void main(String[] args) &#123; URL[] urls = sun.misc.Launcher.getBootstrapClassPath().getURLs(); for (int i = 0; i &lt; urls.length; i++) &#123; System.out.println(urls[i].toExternalForm()); &#125; &#125;&#125; 以下内容是上述程序从本机JDK环境所获得的结果： 其实上述结果也是通过查找sun.boot.class.path这个系统属性所得知的。 1System.out.println(System.getProperty(&quot;sun.boot.class.path&quot;)); 1打印结果：C:\\Java\\jdk1.8.0_60\\jre\\lib\\resources.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\rt.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\sunrsasign.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\jsse.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\jce.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\charsets.jar;C:\\Java\\jdk1.8.0_60\\jre\\lib\\jfr.jar;C:\\Java\\jdk1.8.0_60\\jre\\classes Extension ClassLoader：称为扩展类加载器，负责加载Java的扩展类库，Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。默认加载JAVA_HOME/jre/lib/ext/目下的所有jar。 App ClassLoader：称为系统类加载器，负责加载应用程序classpath目录下的所有jar和class文件。一般来说，Java 应用的类都是由它来完成加载的。可以通过ClassLoader.getSystemClassLoader()来获取它。 除了系统提供的类加载器以外，开发人员可以通过继承java.lang.ClassLoader类的方式实现自己的类加载器，以满足一些特殊的需求。 除了引导类加载器之外，所有的类加载器都有一个父类加载器。 给出的 getParent()方法可以得到。对于系统提供的类加载器来说，系统类加载器的父类加载器是扩展类加载器，而扩展类加载器的父类加载器是引导类加载器；对于开发人员编写的类加载器来说，其父类加载器是加载此类加载器 Java 类的类加载器。因为类加载器 Java 类如同其它的 Java 类一样，也是要由类加载器来加载的。一般来说，开发人员编写的类加载器的父类加载器是系统类加载器。类加载器通过这种方式组织起来，形成树状结构。树的根节点就是引导类加载器。 ClassLoader加载类的原理原理介绍ClassLoader使用的是双亲委托模型来搜索类的，每个ClassLoader实例都有一个父类加载器的引用（不是继承的关系，是一个包含的关系），虚拟机内置的类加载器（Bootstrap ClassLoader）本身没有父类加载器，但可以用作其它ClassLoader实例的的父类加载器。当一个ClassLoader实例需要加载某个类时，它会试图亲自搜索某个类之前，先把这个任务委托给它的父类加载器，这个过程是由上至下依次检查的，首先由最顶层的类加载器Bootstrap ClassLoader试图加载，如果没加载到，则把任务转交给Extension ClassLoader试图加载，如果也没加载到，则转交给App ClassLoader进行加载，如果它也没有加载得到的话，则返回给委托的发起者，由它到指定的文件系统或网络等URL中加载该类。如果它们都没有加载到这个类时，则抛出ClassNotFoundException异常。否则将这个找到的类生成一个类的定义，并将它加载到内存当中，最后返回这个类在内存中的Class实例对象。 为什么要使用双亲委托这种模型呢？因为这样可以避免重复加载，当父亲已经加载了该类的时候，就没有必要 ClassLoader再加载一次。考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时就被引导类加载器（Bootstrcp ClassLoader）加载，所以用户自定义的ClassLoader永远也无法加载一个自己写的String，除非你改变JDK中ClassLoader搜索类的默认算法。 但是JVM在搜索类的时候，又是如何判定两个class是相同的呢？JVM在判定两个class是否相同时，不仅要判断两个类名是否相同，而且要判断是否由同一个类加载器实例加载的。只有两者同时满足的情况下，JVM才认为这两个class是相同的。就算两个class是同一份class字节码，如果被两个不同的ClassLoader实例所加载，JVM也会认为它们是两个不同class。比如网络上的一个Java类org.classloader.simple.NetClassLoaderSimple，javac编译之后生成字节码文件NetClassLoaderSimple.class，ClassLoaderA和ClassLoaderB这两个类加载器并读取了NetClassLoaderSimple.class文件，并分别定义出了java.lang.Class实例来表示这个类，对于JVM来说，它们是两个不同的实例对象，但它们确实是同一份字节码文件，如果试图将这个Class实例生成具体的对象进行转换时，就会抛运行时异常java.lang.ClassCaseException，提示这是两个不同的类型。现在通过实例来验证上述所描述的是否正确：1）、在web服务器上建一个org.classloader.simple.NetClassLoaderSimple.java类 1234567public class NetClassLoaderSimple&#123; private NetClassLoaderSimple instance; public void setNetClassLoaderSimple(Object object)&#123; this.instance = (NetClassLoaderSimple)object; &#125;&#125; org.classloader.simple.NetClassLoaderSimple类的setNetClassLoaderSimple方法接收一个Object类型参数，并将它强制转换成org.classloader.simple.NetClassLoaderSimple类型。 2）、测试两个class是否相同 NetWorkClassLoader.java 12345678910111213141516171819package classloader;public class NewworkClassLoaderTest &#123; public static void main(String[] args) &#123; try &#123; //测试加载网络中的class文件 String rootUrl = &quot;http://localhost:8080/httpweb/classes&quot;; String className = &quot;org.classloader.simple.NetClassLoaderSimple&quot;; NetworkClassLoader ncl1 = new NetworkClassLoader(rootUrl); NetworkClassLoader ncl2 = new NetworkClassLoader(rootUrl); Class&lt;?&gt; clazz1 = ncl1.loadClass(className); Class&lt;?&gt; clazz2 = ncl2.loadClass(className); Object obj1 = clazz1.newInstance(); Object obj2 = clazz2.newInstance(); clazz1.getMethod(&quot;setNetClassLoaderSimple&quot;, Object.class).invoke(obj1, obj2); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 首先获得网络上一个class文件的二进制名称，然后通过自定义的类加载器NetworkClassLoader创建两个实例，并根据网络地址分别加载这份class，并得到这两个ClassLoader实例加载后生成的Class实例clazz1和clazz2，最后将这两个Class实例分别生成具体的实例对象obj1和obj2，再通过反射调用clazz1中的setNetClassLoaderSimple方法。 3）、查看测试结果 结论：从结果中可以看出，运行时抛出了java.lang.ClassCastException异常。虽然两个对象obj1和 obj2的类的名字相同，但是这两个类是由不同的类加载器实例来加载的，所以JVM认为它们就是两个不同的类。 了解了这一点之后，就可以理解代理模式的设计动机了。代理模式是为了保证 Java 核心库的类型安全。所有 Java 应用都至少需要引用 java.lang.Object类，也就是说在运行的时候，java.lang.Object这个类需要被加载到 Java 虚拟机中。如果这个加载过程由 Java 应用自己的类加载器来完成的话，很可能就存在多个版本的java.lang.Object类，而且这些类之间是不兼容的。通过代理模式，对于 Java 核心库的类的加载工作由引导类加载器来统一完成，保证了Java 应用所使用的都是同一个版本的 Java 核心库的类，是互相兼容的。 不同的类加载器为相同名称的类创建了额外的名称空间。相同名称的类可以并存在 Java 虚拟机中，只需要用不同的类加载器来加载它们即可。不同类加载器加载的类之间是不兼容的，这就相当于在 Java 虚拟机内部创建了一个个相互隔离的 Java 类空间。 ClassLoader的体系架构 类加载器的树状组织结构测试一: 1234567891011public class ClassLoaderTree&#123; public static void main(String[] args) &#123; ClassLoader loader = ClassLoaderTree.class.getClassLoader(); while (loader!=null)&#123; System.out.println(loader.toString()); loader = loader.getParent(); &#125; System.out.println(loader); &#125;&#125; 每个 Java 类都维护着一个指向定义它的类加载器的引用，通过 getClassLoader()方法就可以获取到此引用。代码中通过递归调用 getParent()方法来输出全部的父类加载器。 结果是： 第一个输出的是ClassLoaderTree类的类加载器，即系统类加载器。它是sun.misc.Launcher$AppClassLoader类的实例；第二个输出的是扩展类加载器，是sun.misc.Launcher$ExtClassLoader类的实例。需要注意的是这里并没有输出引导类加载器，这是由于有些 JDK 的实现对于父类加载器是引导类加载器的情况,getParent()方法返回 null。第三行结果说明：ExtClassLoader的类加器是Bootstrap ClassLoader，因为Bootstrap ClassLoader不是一个普通的Java类，所以ExtClassLoader的parent=null，所以第三行的打印结果为null就是这个原因。 测试二:将ClassLoaderTree.class打包成ClassLoaderTree.jar，放到Extension ClassLoader的加载目录下（·JAVA_HOME/jre/lib/ext`），然后重新运行这个程序，得到的结果会是什么样呢？ 此处我在 IDEA 中的运行结果还和上面的一样，与文章 深入分析Java ClassLoader原理 中的有差距，具体原因未弄清楚，还希望读者能够亲自测试。 那文章中的结果是： 打印结果分析：为什么第一行的结果是ExtClassLoader呢？ 因为 ClassLoader 的委托模型机制，当我们要用 ClassLoaderTest.class 这个类的时候，AppClassLoader 在试图加载之前，先委托给 Bootstrcp ClassLoader，Bootstracp ClassLoader 发现自己没找到，它就告诉 ExtClassLoader，兄弟，我这里没有这个类，你去加载看看，然后 Extension ClassLoader 拿着这个类去它指定的类路径（JAVA_HOME/jre/lib/ext）试图加载，唉，它发现在ClassLoaderTest.jar这样一个文件中包含 ClassLoaderTest.class 这样的一个文件，然后它把找到的这个类加载到内存当中，并生成这个类的 Class 实例对象，最后把这个实例返回。所以 ClassLoaderTest.class 的类加载器是 ExtClassLoader。 第二行的结果为null，是因为ExtClassLoader的父类加载器是Bootstrap ClassLoader。 JVM加载class文件的两种方法 隐式加载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中。 显式加载， 通过class.forname()、this.getClass.getClassLoader().loadClass()等方法显式加载需要的类，或者我们自己实现的 ClassLoader 的 findlass() 方法。 下面介绍下 class.forName的加载类方法： Class.forName是一个静态方法，同样可以用来加载类。该方法有两种形式：Class.forName(String name,boolean initialize, ClassLoader loader)和Class.forName(String className)。第一种形式的参数 name表示的是类的全名；initialize表示是否初始化类；loader表示加载时使用的类加载器。第二种形式则相当于设置了参数 initialize的值为 true，loader的值为当前类的类加载器。Class.forName的一个很常见的用法是在加载数据库驱动的时候。如Class.forName(&quot;org.apache.derby.jdbc.EmbeddedDriver&quot;)用来加载 Apache Derby 数据库的驱动。 类加载的动态性体现一个应用程序总是由n多个类组成，Java程序启动时，并不是一次把所有的类全部加载后再运行，它总是先把保证程序运行的基础类一次性加载到jvm中，其它类等到jvm用到的时候再加载，这样的好处是节省了内存的开销，因为java最早就是为嵌入式系统而设计的，内存宝贵，这是一种可以理解的机制，而用到时再加载这也是java动态性的一种体现。 如何加载 class 文件 第一阶段找到 .class 文件并把这个文件包含的字节码加载到内存中。 第二阶段中分三步，字节码验证；class 类数据结构分析及相应的内存分配；最后的符号表的链接。 第三阶段是类中静态属性和初始化赋值，以及静态块的执行等。 验证与分析 字节码验证，类装入器对于类的字节码要做很多检测，以确保格式正确，行为正确。 类装备，准备代表每个类中定义的字段、方法和实现接口所必须的数据结构。 解析，装入器装入类所引用的其他所有类。 常见加载类错误分析ClassNotFoundExecptionClassNotFoundExecption 异常是平常碰到的最多的。这个异常通常发生在显示加载类的时候。 12345678910public class ClassNotFoundExceptionTest&#123; public static void main(String[] args) &#123; try &#123; Class.forName(&quot;NotFoundClass&quot;); &#125;catch (ClassNotFoundException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 显示加载一个类通常有： 通过类 Class 中的 forName() 方法 通过类 ClassLoader 中的 loadClass() 方法 通过类 ClassLoader 中的 findSystemClass() 方法 出现这种错误其实就是当 JVM 要加载指定文件的字节码到内存时，并没有找到这个文件对应的字节码，也就是这个文件并不存在。解决方法就是检查在当前的 classpath 目录下有没有指定的文件。 NoClassDefFoundError在JavaDoc中对NoClassDefFoundError的产生可能的情况就是使用new关键字、属性引用某个类、继承了某个接口或者类，以及方法的某个参数中引用了某个类，这时就会触发JVM或者类加载器实例尝试加载类型的定义，但是该定义却没有找到，影响了执行路径。换句话说，在编译时这个类是能够被找到的，但是在执行时却没有找到。 解决这个错误的方法就是确保每个类引用的类都在当前的classpath下面。 UnsatisfiedLinkError该错误通常是在 JVM 启动的时候，如果 JVM 中的某个 lib 删除了，就有可能报这个错误。 12345678910public class UnsatisfiedLinkErrorTest&#123; public native void nativeMethod(); static &#123; System.loadLibrary(&quot;NoLib&quot;); &#125; public static void main(String[] args) &#123; new UnsatisfiedLinkErrorTest().nativeMethod(); //解析native标识的方法时JVM找不到对应的库文件 &#125;&#125; ClassCastException该错误通常出现强制类型转换时出现这个错误。 123456789101112public class ClassCastExceptionTest&#123; public static Map m = new HashMap()&#123; &#123; put(&quot;a&quot;, &quot;2&quot;); &#125; &#125;; public static void main(String[] args) &#123; Integer integer = (Integer) m.get(&quot;a&quot;); //将m强制转换成Integer类型 System.out.println(integer); &#125;&#125; 注意：JVM 在做类型转换时的规则： 对于普通对象，对象必须是目标类的实例或目标类的子类的实例。如果目标类是接口，那么会把它当作实现了该接口的一个子类。 对于数组类型，目标类必须是数组类型或 java.lang.Object、java.lang.Cloneable、java.io.Serializable。 如果不满足上面的规则，JVM 就会报错，有两种方式可避免错误： 在容器类型中显式的指明这个容器所包含的对象类型。 先通过 instanceof 检查是不是目标类型，然后再进行强制类型的转换。 上面代码中改成如下就可以避免错误了： ExceptionInInitializerError12345678910public class ExceptionInInitializerErrorTest&#123; public static Map m = new HashMap()&#123;&#123; m.put(&quot;a&quot;, &quot;2&quot;); &#125;&#125;; public static void main(String[] args) &#123; Integer integer = (Integer) m.get(&quot;a&quot;); System.out.println(integer); &#125;&#125; 在初始化这个类时，给静态属性 m 赋值时出现了异常导致抛出错误 ExceptionInInitializerError。 NoSuchMethodErrorNoSuchMethodError代表这个类型确实存在，但是一个不正确的版本被加载了。为了解决这个问题我们可以使用 ‘verbose:class’ 来判断该JVM加载的到底是哪个版本。 LinkageError有时候事情会变得更糟，和 ClassCastException 本质一样，加载自不同位置的相同类在同一段逻辑（比如：方法）中交互时，会出现 LinkageError 。 LinkageError 需要观察哪个类被不同的类加载器加载了，在哪个方法或者调用处发生（交汇）的，然后才能想解决方法，解决方法无外乎两种。第一，还是不同的类加载器加载，但是相互不再交汇影响，这里需要针对发生问题的地方做一些改动，比如更换实现方式，避免出现上述问题；第二，冲突的类需要由一个Parent类加载器进行加载。LinkageError 和ClassCastException 本质是一样的，加载自不同类加载器的类型，在同一个类的方法或者调用中出现，如果有转型操作那么就会抛 ClassCastException ，如果是直接的方法调用处的参数或者返回值解析，那么就会产生 LinkageError 。 常用的 ClassLoader 分析。。参见书籍《深入分析Java Web技术内幕》 如何实现自己的 ClassLoaderClassLoader 能够完成的事情有以下情况： 在自定义路径下查找自定义的class类文件。 对我们自己要加载的类做特殊处理。 可以定义类的实现机制。 虽然在绝大多数情况下，系统默认提供的类加载器实现已经可以满足需求。但是在某些情况下，您还是需要为应用开发出自己的类加载器。比如您的应用通过网络来传输 Java 类的字节代码，为了保证安全性，这些字节代码经过了加密处理。这个时候您就需要自己的类加载器来从某个网络地址上读取加密后的字节代码，接着进行解密和验证，最后定义出要在 Java 虚拟机中运行的类来 定义自已的类加载器分为两步：1、继承java.lang.ClassLoader2、重写父类的findClass方法 文件系统类加载器加载存储在文件系统上的 Java 字节代码。 1234567891011121314151617181920212223242526272829303132333435363738public class FileSystemClassLoader extends ClassLoader&#123; private String rootDir; public FileSystemClassLoader(String rootDir)&#123; this.rootDir = rootDir; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null)&#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; while ((bytesNumRead = ins.read(buffer)) != -1)&#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootDir + File.separatorChar + className.replace(&apos;.&apos;, File.separatorChar) + &quot;.class&quot;; &#125;&#125; 类FileSystemClassLoader继承自类java.lang.ClassLoader。java.lang.ClassLoader类的方法loadClass()封装了前面提到的代理模式的实现。该方法会首先调用 findLoadedClass()方法来检查该类是否已经被加载过；如果没有加载过的话，会调用父类加载器的loadClass()方法来尝试加载该类；如果父类加载器无法加载该类的话，就调用 findClass()方法来查找该类。因此，为了保证类加载器都正确实现代理模式，在开发自己的类加载器时，最好不要覆写 loadClass()方法，而是覆写findClass()方法。 类 FileSystemClassLoader的 findClass()方法首先根据类的全名在硬盘上查找类的字节代码文件（.class 文件），然后读取该文件内容，最后通过 defineClass()方法来把这些字节代码转换成 java.lang.Class类的实例。 网络类加载器一个网络类加载器来说明如何通过类加载器来实现组件的动态更新。即基本的场景是：Java 字节代码（.class）文件存放在服务器上，客户端通过网络的方式获取字节代码并执行。当有版本更新的时候，只需要替换掉服务器上保存的文件即可。通过类加载器可以比较简单的实现这种需求。 类 NetworkClassLoader 负责通过网络下载 Java 类字节代码并定义出 Java 类。它的实现与FileSystemClassLoader 类似。在通过 NetworkClassLoader 加载了某个版本的类之后，一般有两种做法来使用它。第一种做法是使用 Java 反射 API。另外一种做法是使用接口。需要注意的是，并不能直接在客户端代码中引用从服务器上下载的类，因为客户端代码的类加载器找不到这些类。使用 Java 反射 API 可以直接调用 Java 类的方法。而使用接口的做法则是把接口的类放在客户端中，从服务器上加载实现此接口的不同版本的类。在客户端通过相同的接口来使用这些实现类。 网络类加载器的代码：ClassLoader 类加载器与Web容器对于运行在 Java EE™容器中的 Web 应用来说，类加载器的实现方式与一般的 Java 应用有所不同。不同的 Web 容器的实现方式也会有所不同。以 Apache Tomcat 来说，每个Web 应用都有一个对应的类加载器实例。该类加载器也使用代理模式，所不同的是它是首先尝试去加载某个类，如果找不到再代理给父类加载器。这与一般类加载器的顺序是相反的。这是 Java Servlet 规范中的推荐做法，其目的是使得Web 应用自己的类的优先级高于 Web 容器提供的类。这种代理模式的一个例外是：Java 核心库的类是不在查找范围之内的。这也是为了保证 Java 核心库的类型安全。 绝大多数情况下，Web 应用的开发人员不需要考虑与类加载器相关的细节。下面给出几条简单的原则： 每个 Web 应用自己的 Java 类文件和使用的库的 jar 包，分别放在 WEB-INF/classes和 WEB-INF/lib目录下面。 多个应用共享的 Java 类文件和 jar 包，分别放在 Web 容器指定的由所有 Web 应用共享的目录下面。 当出现找不到类的错误时，检查当前类的类加载器和当前线程的上下文类加载器是否正确 结本篇文章详细深入的介绍了 ClassLoader 的工作机制，还写了如何自己实现所需的 ClassLoader 。 文中阐述不妥之处还望雅正，不吝感激。 转载请注明出处:天雷 以上。 参考资料1、深度分析 Java 的 ClassLoader 机制 -源码级别 2、深入浅出ClassLoader 3、深入探讨 Java 类加载器 4、深入分析Java ClassLoader原理 5、《深入分析 Java Web 技术内幕》修订版 —— 深入分析 ClassLoader 工作机制 6、详细深入分析 Java ClassLoader 工作机制","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://54skyray.cn/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://54skyray.cn/tags/JVM/"},{"name":"类加载机制","slug":"类加载机制","permalink":"http://54skyray.cn/tags/类加载机制/"}]},{"title":"Hello","slug":"Hello","date":"2015-12-11T08:18:27.000Z","updated":"2017-12-20T09:35:40.521Z","comments":true,"path":"2015/12/11/Hello/","link":"","permalink":"http://54skyray.cn/2015/12/11/Hello/","excerpt":"","text":"今天开通这个博客，遗憾的是之前都没有开通博客去学习的同时，将成果共享。用心更新博客，与各位因特网大佬共同成长。。。。","categories":[],"tags":[{"name":"first time","slug":"first-time","permalink":"http://54skyray.cn/tags/first-time/"}]}]}